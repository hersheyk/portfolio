[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Harshini Karthikeyan",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\nMy name is Harshini Karthikeyan, this website is a collection of my work"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Generative Art\n\n\n\n\n\n\nHarshini Karthikeyan\n\n\nJun 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWebscraping\n\n\n\n\n\n\nHarshini Karthikeyan\n\n\nMay 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJSON and APIs\n\n\n\n\n\n\nHarshini Karthikeyan\n\n\nMay 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWriting Efficient Functions\n\n\n\n\n\n\nHarshini Karthikeyan\n\n\nMay 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatic Quarto Dashboards\n\n\n\n\n\n\nHarshini Karthikeyan\n\n\nApr 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizations\n\n\n\n\n\n\nHarshini Karthikeyan\n\n\nApr 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteractive Quarto Dashboards\n\n\n\n\n\n\nHarshini Karthikeyan\n\n\nApr 10, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2025-05-05-midterm-reflection/index.html",
    "href": "posts/2025-05-05-midterm-reflection/index.html",
    "title": "Dashboard",
    "section": "",
    "text": "test working in progress"
  },
  {
    "objectID": "posts/2025-05-01-Quarto Dashboards (Dynamic)/index.html",
    "href": "posts/2025-05-01-Quarto Dashboards (Dynamic)/index.html",
    "title": "Dynamic Quarto Dashboards",
    "section": "",
    "text": "test 2"
  },
  {
    "objectID": "posts/2025-05-01-Visualizations/visualizations.html",
    "href": "posts/2025-05-01-Visualizations/visualizations.html",
    "title": "Visualizations",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readxl)\nlibrary(ggrepel)\nlibrary(scales)\nlibrary(leaflet)\n\nlibrary(rnaturalearth)\nlibrary(sf)\nlibrary(rnaturalearthdata)\n\n\n\n\nWhile there are certainly issues with this image, do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\nI believe this plot is trying to show us the proportion of people in a particular country that believe a vaccine is safe. It shows us one observation per country where the y-axis appears to be country? It also sorted the observations by proportion, so that it appears that the proportions increase as the y-axis goes up.\n\nList the variables that appear to be displayed in this visualization. Hint: Variables refer to columns in the data.\n\nThe country, the global region of the country and the percentage of people in the country that believe a vaccine is safe.\n\nNow that you’re versed in the grammar of graphics (e.g., ggplot), list the aesthetics used and which variables are mapped to each.\n\nThe x-axis the percentage of people in the country that believe a vaccine is safe. The y-axis is the country, the color is filled by global region.\n\nWhat type of graph would you call this? Meaning, what geom would you use to produce this plot?\n\nI would call this a scatter plot and would use geom point to produce it.\n\nProvide at least four problems or changes that would improve this graph. Please format your changes as bullet points!\n\n\nI think this is a graph that is faceted by region of the world, but it lends to a strange stacked graph like view that is not very intuitive, and leaves some plots stranded from their axes. I would try faceting differently or trying to remove the facet entirely.\nI think having the y-axis be the countries is a bit strange, and that sorting it by the proportion feels odd, as though it is increasing over time or something, I would try sorting it alphabetically or removing the y-axis and making it a box-plot instead.\nI think having the legend at the bottom is unnecessary as the global region is also written directly onto each facet of the plot, so I would remove one of those, preferably the legend, depending on how my plot turns out.\nI think having to state that the dark vertical lines represent region medians but also not writing the number of each on the plot itself is confusing and forces the reader to then look for th median by finding the axis\n\n\n\n\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\ndata&lt;-read_excel(\"C:\\\\Users\\\\Geetha\\\\Downloads\\\\wgm2018-dataset-crosstabs-all-countries.xlsx\")\n\n\nnational &lt;- data[c('...1', '...2', '...3', 'National results','...5')]\ncolnames(national) &lt;- c(\"Country\", \"Question\", \"Response\", \"National_Results_Col_Per\", \"National_Results_Count\")\n\nnational &lt;- national[!(national$Country %in% c(NA, 'Country')),]\n#drop title row since renamed cols alr\n\n\nnational$QNumber &lt;- str_split_i(national$Question, \" \", 1)\n\n\nasia &lt;- c('Afghanistan', 'Bangladesh', 'Cambodia', 'China', 'India', 'Indonesia', 'Japan', 'Laos', 'Malaysia', 'Mongolia', 'Myanmar', 'Nepal', 'Pakistan', 'Philippines', 'Singapore', 'South Korea', 'Sri Lanka', 'Taiwan', 'Thailand', 'Vietnam'\n)\n\nmena &lt;- c('Algeria', 'Egypt', 'Iran', 'Iraq', 'Israel', 'Jordan', 'Kuwait', 'Lebanon','Libya', 'Morocco', 'Palestine', 'Saudi Arabia', 'Tunisia', 'United Arab Emirates', 'Yemen'\n)\n\namericas &lt;- c('Argentina', 'Bolivia', 'Brazil', 'Canada', 'Chile', 'Colombia', 'Costa Rica', 'Dominican Republic', 'Ecuador', 'El Salvador', 'Guatemala', \"Haiti\", 'Honduras','Mexico', 'Nicaragua', 'Panama', 'Paraguay', 'Peru', 'United States', 'Uruguay', 'Venezuela'\n)\n\nsub_sahara &lt;- c('Benin', 'Botswana', 'Burkina Faso', 'Burundi', 'Cameroon', 'Congo, Rep.','Comoros', 'Chad','Eswatini','Ethiopia', 'Gabon', 'Ghana', 'Guinea', 'Ivory Coast', 'Kenya', 'Liberia', 'Madagascar', 'Malawi', 'Mali', 'Mauritania', 'Mauritius','Mozambique', 'Namibia', 'Niger', 'Nigeria', 'Rwanda', 'Senegal','Sierra Leone', 'South Africa', 'Tanzania', 'The Gambia', 'Togo','Uganda', 'Zambia', 'Zimbabwe'\n)\n\neurope &lt;- c('Albania', 'Austria', 'Belgium', 'Bosnia and Herzegovina', 'Bulgaria','Croatia', 'Cyprus', 'Czech Republic', 'Denmark', 'Finland', 'France','Germany', 'Greece', 'Hungary', 'Iceland', 'Ireland', 'Italy', 'Kosovo','Luxembourg', 'Macedonia', 'Malta', 'Netherlands', 'Norway', \"Poland\", 'Northern Cyprus', 'Montenegro', 'Portugal', 'Romania', 'Serbia', 'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'Switzerland', 'Turkey', 'United Kingdom'\n)\n\nformer_soviet &lt;- c('Armenia', 'Azerbaijan', 'Belarus', 'Estonia', 'Georgia', 'Kazakhstan', 'Kyrgyzstan', 'Latvia', 'Lithuania', 'Moldova', 'Russia', 'Tajikistan', 'Ukraine', 'Uzbekistan', 'Turkmenistan'\n)\n\noceania &lt;- c('Australia', 'New Zealand')\n\n\nnational1 &lt;- national |&gt;\n  fill(QNumber, .direction = \"down\") |&gt;\n  #Source for .direction: https://tidyr.tidyverse.org/reference/fill.html\n  filter(QNumber == \"Q25\") |&gt;\n  filter(Response == \"Strongly agree\" | Response == \"Somewhat agree\") |&gt; group_by(Country) |&gt;\n  summarize(Agree_Percent = sum(as.numeric(National_Results_Col_Per)), .groups = \"drop\") |&gt; \n  mutate(Region = case_when(\n    Country %in% asia ~ \"Asia\",\n    Country %in% mena ~ \"Middle East and North Africa\",\n    Country %in% americas ~ \"Americas\",\n    Country %in% sub_sahara ~ \"Sub-Saharan Africa\",\n    Country %in% europe ~ \"Europe\",\n    Country %in% former_soviet ~ \"Former Soviet Union\",\n    Country %in% oceania ~ \"Oceania\",\n    \n    TRUE ~ \"Other\" #used to check, there are none that fall in this category\n  ))\n  #summarize function : https://stackoverflow.com/questions/62891736/sum-sub-groups-with-dplyr\n\n\noutliers &lt;- national1|&gt;\n  group_by(Region)|&gt;\n  mutate(\n    Q1 = quantile(Agree_Percent, 0.25),  Q3 = quantile(Agree_Percent, 0.75),\n    IQR = Q3 - Q1,\n    is_outlier = Agree_Percent &lt; (Q1 - 1.5 * IQR) | Agree_Percent &gt; (Q3 + 1.5 * IQR)\n  ) |&gt;\n  filter(is_outlier)\n\n\n\n#layout-ncol: 2\n#knitr::include_graphics(\"images/Capture3.jpg\")\n\n#https://stackoverflow.com/questions/77144719/how-to-embed-an-image-into-a-quarto-document-in-r\n\n\nggplot(national1, aes(x = Region,y=Agree_Percent,fill = Region))+\n  geom_boxplot(outlier.shape= NA,alpha = 0.7) +  \n  geom_point(data = outliers, aes(x =Region, y= Agree_Percent), shape =16, size =3, color = \"black\") +\n  geom_text(\n    data =outliers,\n    aes(label= Country), vjust =0.25, hjust=-0.25,  size = 4, family=\"serif\"\n  )+ scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    title = \"The Percentage of People Who Believe Vaccines are Safe by Global Region\",\n    x= \"Region\",y= NULL,\n  ) +theme_minimal(base_family = \"serif\")+\n  \n  theme(axis.text.x = element_text(angle = 20, hjust = 0.75), axis.text = element_text(size = 10,color = \"black\"), legend.position = \"none\"\n        )"
  },
  {
    "objectID": "posts/2025-05-01-Visualizations/visualizations.html#part-1",
    "href": "posts/2025-05-01-Visualizations/visualizations.html#part-1",
    "title": "Visualizations",
    "section": "",
    "text": "While there are certainly issues with this image, do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\nI believe this plot is trying to show us the proportion of people in a particular country that believe a vaccine is safe. It shows us one observation per country where the y-axis appears to be country? It also sorted the observations by proportion, so that it appears that the proportions increase as the y-axis goes up.\n\nList the variables that appear to be displayed in this visualization. Hint: Variables refer to columns in the data.\n\nThe country, the global region of the country and the percentage of people in the country that believe a vaccine is safe.\n\nNow that you’re versed in the grammar of graphics (e.g., ggplot), list the aesthetics used and which variables are mapped to each.\n\nThe x-axis the percentage of people in the country that believe a vaccine is safe. The y-axis is the country, the color is filled by global region.\n\nWhat type of graph would you call this? Meaning, what geom would you use to produce this plot?\n\nI would call this a scatter plot and would use geom point to produce it.\n\nProvide at least four problems or changes that would improve this graph. Please format your changes as bullet points!\n\n\nI think this is a graph that is faceted by region of the world, but it lends to a strange stacked graph like view that is not very intuitive, and leaves some plots stranded from their axes. I would try faceting differently or trying to remove the facet entirely.\nI think having the y-axis be the countries is a bit strange, and that sorting it by the proportion feels odd, as though it is increasing over time or something, I would try sorting it alphabetically or removing the y-axis and making it a box-plot instead.\nI think having the legend at the bottom is unnecessary as the global region is also written directly onto each facet of the plot, so I would remove one of those, preferably the legend, depending on how my plot turns out.\nI think having to state that the dark vertical lines represent region medians but also not writing the number of each on the plot itself is confusing and forces the reader to then look for th median by finding the axis"
  },
  {
    "objectID": "posts/2025-05-01-Visualizations/visualizations.html#improving-the-bad-visualization",
    "href": "posts/2025-05-01-Visualizations/visualizations.html#improving-the-bad-visualization",
    "title": "Visualizations",
    "section": "",
    "text": "Improve the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\ndata&lt;-read_excel(\"C:\\\\Users\\\\Geetha\\\\Downloads\\\\wgm2018-dataset-crosstabs-all-countries.xlsx\")\n\n\nnational &lt;- data[c('...1', '...2', '...3', 'National results','...5')]\ncolnames(national) &lt;- c(\"Country\", \"Question\", \"Response\", \"National_Results_Col_Per\", \"National_Results_Count\")\n\nnational &lt;- national[!(national$Country %in% c(NA, 'Country')),]\n#drop title row since renamed cols alr\n\n\nnational$QNumber &lt;- str_split_i(national$Question, \" \", 1)\n\n\nasia &lt;- c('Afghanistan', 'Bangladesh', 'Cambodia', 'China', 'India', 'Indonesia', 'Japan', 'Laos', 'Malaysia', 'Mongolia', 'Myanmar', 'Nepal', 'Pakistan', 'Philippines', 'Singapore', 'South Korea', 'Sri Lanka', 'Taiwan', 'Thailand', 'Vietnam'\n)\n\nmena &lt;- c('Algeria', 'Egypt', 'Iran', 'Iraq', 'Israel', 'Jordan', 'Kuwait', 'Lebanon','Libya', 'Morocco', 'Palestine', 'Saudi Arabia', 'Tunisia', 'United Arab Emirates', 'Yemen'\n)\n\namericas &lt;- c('Argentina', 'Bolivia', 'Brazil', 'Canada', 'Chile', 'Colombia', 'Costa Rica', 'Dominican Republic', 'Ecuador', 'El Salvador', 'Guatemala', \"Haiti\", 'Honduras','Mexico', 'Nicaragua', 'Panama', 'Paraguay', 'Peru', 'United States', 'Uruguay', 'Venezuela'\n)\n\nsub_sahara &lt;- c('Benin', 'Botswana', 'Burkina Faso', 'Burundi', 'Cameroon', 'Congo, Rep.','Comoros', 'Chad','Eswatini','Ethiopia', 'Gabon', 'Ghana', 'Guinea', 'Ivory Coast', 'Kenya', 'Liberia', 'Madagascar', 'Malawi', 'Mali', 'Mauritania', 'Mauritius','Mozambique', 'Namibia', 'Niger', 'Nigeria', 'Rwanda', 'Senegal','Sierra Leone', 'South Africa', 'Tanzania', 'The Gambia', 'Togo','Uganda', 'Zambia', 'Zimbabwe'\n)\n\neurope &lt;- c('Albania', 'Austria', 'Belgium', 'Bosnia and Herzegovina', 'Bulgaria','Croatia', 'Cyprus', 'Czech Republic', 'Denmark', 'Finland', 'France','Germany', 'Greece', 'Hungary', 'Iceland', 'Ireland', 'Italy', 'Kosovo','Luxembourg', 'Macedonia', 'Malta', 'Netherlands', 'Norway', \"Poland\", 'Northern Cyprus', 'Montenegro', 'Portugal', 'Romania', 'Serbia', 'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'Switzerland', 'Turkey', 'United Kingdom'\n)\n\nformer_soviet &lt;- c('Armenia', 'Azerbaijan', 'Belarus', 'Estonia', 'Georgia', 'Kazakhstan', 'Kyrgyzstan', 'Latvia', 'Lithuania', 'Moldova', 'Russia', 'Tajikistan', 'Ukraine', 'Uzbekistan', 'Turkmenistan'\n)\n\noceania &lt;- c('Australia', 'New Zealand')\n\n\nnational1 &lt;- national |&gt;\n  fill(QNumber, .direction = \"down\") |&gt;\n  #Source for .direction: https://tidyr.tidyverse.org/reference/fill.html\n  filter(QNumber == \"Q25\") |&gt;\n  filter(Response == \"Strongly agree\" | Response == \"Somewhat agree\") |&gt; group_by(Country) |&gt;\n  summarize(Agree_Percent = sum(as.numeric(National_Results_Col_Per)), .groups = \"drop\") |&gt; \n  mutate(Region = case_when(\n    Country %in% asia ~ \"Asia\",\n    Country %in% mena ~ \"Middle East and North Africa\",\n    Country %in% americas ~ \"Americas\",\n    Country %in% sub_sahara ~ \"Sub-Saharan Africa\",\n    Country %in% europe ~ \"Europe\",\n    Country %in% former_soviet ~ \"Former Soviet Union\",\n    Country %in% oceania ~ \"Oceania\",\n    \n    TRUE ~ \"Other\" #used to check, there are none that fall in this category\n  ))\n  #summarize function : https://stackoverflow.com/questions/62891736/sum-sub-groups-with-dplyr\n\n\noutliers &lt;- national1|&gt;\n  group_by(Region)|&gt;\n  mutate(\n    Q1 = quantile(Agree_Percent, 0.25),  Q3 = quantile(Agree_Percent, 0.75),\n    IQR = Q3 - Q1,\n    is_outlier = Agree_Percent &lt; (Q1 - 1.5 * IQR) | Agree_Percent &gt; (Q3 + 1.5 * IQR)\n  ) |&gt;\n  filter(is_outlier)\n\n\n\n#layout-ncol: 2\n#knitr::include_graphics(\"images/Capture3.jpg\")\n\n#https://stackoverflow.com/questions/77144719/how-to-embed-an-image-into-a-quarto-document-in-r\n\n\nggplot(national1, aes(x = Region,y=Agree_Percent,fill = Region))+\n  geom_boxplot(outlier.shape= NA,alpha = 0.7) +  \n  geom_point(data = outliers, aes(x =Region, y= Agree_Percent), shape =16, size =3, color = \"black\") +\n  geom_text(\n    data =outliers,\n    aes(label= Country), vjust =0.25, hjust=-0.25,  size = 4, family=\"serif\"\n  )+ scale_y_continuous(labels = percent_format(accuracy = 1)) +\n  labs(\n    title = \"The Percentage of People Who Believe Vaccines are Safe by Global Region\",\n    x= \"Region\",y= NULL,\n  ) +theme_minimal(base_family = \"serif\")+\n  \n  theme(axis.text.x = element_text(angle = 20, hjust = 0.75), axis.text = element_text(size = 10,color = \"black\"), legend.position = \"none\"\n        )"
  },
  {
    "objectID": "posts/2025-05-01-Visualizations/visualizations.html#second-data-visualization-improvement",
    "href": "posts/2025-05-01-Visualizations/visualizations.html#second-data-visualization-improvement",
    "title": "Visualizations",
    "section": "Second Data Visualization Improvement",
    "text": "Second Data Visualization Improvement\n\nSelect a data visualization in the report that you think could be improved. Be sure to cite both the page number and figure title. Do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\nChart 5.7: Map of proportions of people reporting vaccinating their children on page 121. This graph is telling us what percentage of the people in a particular country say their children have been vaccinated. It compares between countries, highlighting where this percentage is particularly high or low.\n\n#knitr::include_graphics(\"images/Capture.jpg\")\n\n\nList the variables that appear to be displayed in this visualization.\n\nPercentage of people who answered ‘yes’ to their children having received vaccines and Country,\n\nNow that you’re versed in the grammar of graphics (ggplot), list the aesthetics used and which variables are specified for each.\n\nThe map shows the variable country, the color is filled by the percentage of people who answered ‘yes’.\n\nWhat type of graph would you call this?\n\nI would call this a chloropleth map!\nSource: https://support.esri.com/en-us/gis-dictionary/choropleth-map#:~:text=From%20the%20Greek%20terms%20choro,combining%20different%20sets%20of%20symbols.\n\nList all of the problems or things you would improve about this graph.\n\n\nI would make the color scaling more distinct and more apparent as it is difficult to visibly see the percentage or people who said their children had been vaccinated.\nI might add in global region to see if that shows any distinctions.\nI would make the countries that were not surveyed a more distinct color from the background color as it is hard to notice island nations and the like.\n\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\nnational2 &lt;- national |&gt;\n  fill(QNumber, .direction = \"down\") |&gt;\n  #Source for .direction: https://tidyr.tidyverse.org/reference/fill.html\n  filter(QNumber == \"Q28\")|&gt; filter(Response == \"Yes\") |&gt; mutate(Region = case_when(\n    \n    Country %in% asia ~ \"Asia\",\n    Country %in% mena ~ \"Middle East and North Africa\",\n    Country %in% americas ~ \"Americas\",\n     Country %in% sub_sahara ~ \"Sub-Saharan Africa\",\n    Country %in% europe ~ \"Europe\",\n    \n    Country %in% former_soviet ~ \"Former Soviet Union\",\n    \n    Country %in% oceania ~ \"Oceania\",\n    \n    TRUE ~ \"Other\" #used to check, there are none that fall in this category\n  ))\n\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nworld$Country &lt;- tolower(world$name_long)\nnational2$Country &lt;- tolower(national2$Country)\n\nworld_data &lt;- left_join(world, national2, by = c(\"Country\" = \"Country\"))\nworld_data$National_Results_Col_Per &lt;- as.numeric(world_data$National_Results_Col_Per)\n\n#world_data$National_Results_Col_Per[is.na(world_data$National_Results_Col_Per )] &lt;- \"Countries not surveyed\"\n\n\n#colorpalette\npal &lt;- colorBin(\n  palette =c(\"#ffffd4\", \"#fec44f\", \"#fe9929\", \"#fc4e2a\", \"#b10026\"),\n  #https://loading.io/color/feature/YlOrRd-8\n  domain = world_data$National_Results_Col_Per,\n  bins =c(0, 0.70, 0.80, 0.90, 0.95, 1.00), na.color =\"#d3d3d3\"  \n)\n\n#plot\nleaflet(world_data) |&gt; addTiles() |&gt;\n  addPolygons(\n    fillColor = ~pal(National_Results_Col_Per), weight = 1,\n    color = \"white\", fillOpacity = 0.8,\n    label = ~paste0(Country, \": \", National_Results_Col_Per, \"%\"),\n    highlight = highlightOptions(\n      weight = 2, color = \"#666\",\n      fillOpacity = 0.9, bringToFront = TRUE\n    )\n    #Source: https://r-charts.com/spatial/interactive-maps-leaflet/\n  ) |&gt;\n  \n  addLegend(\n    pal = pal, values = ~National_Results_Col_Per,\n    title = \"Percentage of people who say  &lt;br&gt; their child has been vaccinated\", position = \"bottomright\"\n    #Source line break: https://www.reddit.com/r/Rlanguage/comments/6bsji1/add_line_break_to_leaflet_pop_up/\n  )"
  },
  {
    "objectID": "posts/2025-05-01-Visualizations/visualizations.html#third-data-visualization-improvement",
    "href": "posts/2025-05-01-Visualizations/visualizations.html#third-data-visualization-improvement",
    "title": "Visualizations",
    "section": "Third Data Visualization Improvement",
    "text": "Third Data Visualization Improvement\n\nSelect a data visualization in the report that you think could be improved. Be sure to cite both the page number and figure title. Do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\n\n\n\nList the variables that appear to be displayed in this visualization.\n\nThe percentages for all of the following columns: Men, Women, 15-29, 30-49,50+, Elementary education or less, Secondary education, Post-secondary education, Rural/small town, Big city/suburb,  as well as separate created onee like Parents and Non-Parents\n\nNow that you’re versed in the grammar of graphics (ggplot), list the aesthetics used and which variables are specified for each.\n\nThe x axis is the demographic group while the y-axis is the percentage of the group that believes vaccines are unsafe!\n\nWhat type of graph would you call this?\n\nA bar plot!\n\nList all of the problems or things you would improve about this graph.\n\nI would facet this better and change the background color as the yellow almost blends in with the lighter blue background.\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\nnational3 &lt;- data[c('...1', '...2','...3','National results','...5',\n                    'Gender','...7', '...8', '...9',\n                     'Age Cohort','...11', '...12',\n                    '...13', '...14', '...15', 'General Educational Background', \n                  '...17','...18', '...19', \n                    '...20','...21','Area Type', \n                  '...23', '...24','...25')]\n\ncolnames(national3)&lt;- c(\"Country\", \"Question\", \"Response\",\n                         \"National_Results_Col_Per\", \"National_Results_Count\",\n                         \"Men\", \"Man_num\", \"Women\", \"Woman_num\",\n                         \"15-29\", \"15_29_Num\",\"30-49\",\n                 \"30_49_Num\", \"50+\", \"Above_50_Num\",\n                         \"Elementary education or less\", \"elementary_num\",\n                         \"Secondary education\",\"secondary_num\", \n                         \"Post-secondary education\",\"college_num\", \n                         \"Rural/small town\",\"rural_num\", \n                         \"Big city/suburb\",\"suburb_num\")\n\nnational3 &lt;- national3[!(national3$Country %in% c(NA, 'Country')),]\nnational3$QNumber &lt;- str_split_i(national3$Question, \" \", 1)\n\nnational3 &lt;- national3 |&gt; \n  filter(Country == \"France\")|&gt; fill(QNumber, .direction = \"down\") |&gt;\n  filter(QNumber == \"Q25\")|&gt; filter(Response %in% c(\"Strongly disagree\",\"Somewhat disagree\")) |&gt;\n  mutate(across(c(National_Results_Col_Per, Men, Women, `15-29`, `30-49`,`50+`, \n                  `Elementary education or less`, `Secondary education`, `Post-secondary education`,\n                  `Rural/small town`, `Big city/suburb`),as.numeric)) |&gt;\n  \n  summarize(across(c(National_Results_Col_Per,Men, Women, `15-29`, `30-49`,`50+`, \n                  `Elementary education or less`, `Secondary education`, `Post-secondary education`,\n                  `Rural/small town`, `Big city/suburb`), sum, na.rm = TRUE), .groups = \"drop\")|&gt;\n  mutate(Country = \"France\")\n\nWarning: There was 1 warning in `summarize()`.\nℹ In argument: `across(...)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n\ndata2&lt;-read_excel(\"C:\\\\Users\\\\Geetha\\\\Downloads\\\\wgm2018-dataset-crosstabs-all-countries.xlsx\", sheet = \"Full dataset\")\n\n\n# France's WP5 is 13\nfrance&lt;- data2|&gt; filter( WP5 == 13) |&gt; select(WP5, Q25, Q27)|&gt;group_by(Q27, Q25) |&gt;\n  summarise(count = n(), .groups = \"drop_last\") |&gt;\n  mutate(percentage = round(count / sum(count), 6)) |&gt; ungroup() |&gt;\n  filter(Q25 %in% c(4, 5)) |&gt; group_by(Q27) |&gt;\n  summarise( total_count = sum(count),\n             total_percentage = sum(percentage)) |&gt; pivot_wider(\n    names_from = Q27,\n    values_from = c(total_count, total_percentage),\n    names_glue = \"Q27_{Q27}_{.value}\") |&gt; select(Q27_1_total_percentage, Q27_2_total_percentage) |&gt;mutate(Country = \"France\")\n\n\ncolnames(france) &lt;- c(\"Parents\", \"Non-Parents\", \"Country\")\n\n\nfrance_all&lt;- merge(national3, france, by = \"Country\")\n\n\nfrance_long &lt;- france_all |&gt;\n  pivot_longer(\n    cols = -c(Country, National_Results_Col_Per),\n    names_to = \"Category\",\n    values_to = \"Percentage\"\n  )|&gt;mutate(Group = case_when(\n  Category %in% c(\"Men\", \"Women\") ~ \"Gender\",\n  Category %in% c(\"15-29\", \"30-49\", \"50+\") ~ \"Age\",\n  Category %in% c(\"Elementary education or less\", \"Secondary education\", \"Post-secondary education\") ~ \"Education\",\n  Category %in% c(\"Rural/small town\", \"Big city/suburb\") ~ \"Region\",\n  Category %in% c(\"Parents\", \"Non-Parents\") ~ \"Parenthood\",\n  TRUE ~ \"Other\"\n  ))\nfrance_long\n\n# A tibble: 12 × 5\n   Country National_Results_Col_Per Category                    Percentage Group\n   &lt;chr&gt;                      &lt;dbl&gt; &lt;chr&gt;                            &lt;dbl&gt; &lt;chr&gt;\n 1 France                     0.333 Men                              0.328 Gend…\n 2 France                     0.333 Women                            0.338 Gend…\n 3 France                     0.333 15-29                            0.373 Age  \n 4 France                     0.333 30-49                            0.335 Age  \n 5 France                     0.333 50+                              0.316 Age  \n 6 France                     0.333 Elementary education or le…      0.354 Educ…\n 7 France                     0.333 Secondary education              0.338 Educ…\n 8 France                     0.333 Post-secondary education         0.302 Educ…\n 9 France                     0.333 Rural/small town                 0.352 Regi…\n10 France                     0.333 Big city/suburb                  0.307 Regi…\n11 France                     0.333 Parents                          0.314 Pare…\n12 France                     0.333 Non-Parents                      0.299 Pare…\n\n\nI used ggrepel!\n\nggplot(france_long, aes(x = reorder(Category, Percentage), y = Percentage, fill = Category)) + geom_bar(stat = \"identity\", width = 0.7) + coord_flip() +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  facet_wrap(~ Group, scales = \"free_y\",ncol = 1) +\n  labs(title = \"Proportion of people in France who believe vaccines \\nare unsafe by Demographic Group\",\n       x = \"\",\n       y = \"\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  geom_text_repel(aes(label = round(Percentage, 2)), size = 3, box.padding = 0.3)"
  },
  {
    "objectID": "posts/2025-05-05-dashboard-static/index.html",
    "href": "posts/2025-05-05-dashboard-static/index.html",
    "title": "Quarto Dashboards",
    "section": "",
    "text": "Link to static dashboard:\nhttps://hersheythegr8.quarto.pub/lab-3/#belief-in-vaccine-safety-statistics\nLink to interactive dashboard:\nhttps://ezd0m8-harshini-k.shinyapps.io/lab4/#belief-in-vaccine-safety-statistics"
  },
  {
    "objectID": "reflection-template.html",
    "href": "reflection-template.html",
    "title": "Independent Learning (IL):",
    "section": "",
    "text": "These objectives show your ability to seek out new information and adapt to new tools to solve data analysis problems.\n\n\n\nI can find and adopt new packages to accomplish tasks.\nI can adapt to different syntax styles (tidy, base, formula style, data.table).\n\n\n\n\n\n\ni utilized ggrepel to annotate\nhttps://hersheyk.github.io/portfolio/posts/2025-05-01-Visualizations/visualizations.html#lab-2\n\n\n\n\n\n\nI can use online resources (e.g., Google, ChatGPT, StackOverflow, YouTube) to solve problems, debug, or find new tools.\nI can use tutorials, etc. to enhance my understanding of new concepts.\nI can find source code for similar projects to use as starting points for my own.\n\n\n\n\n\n\nIn Lab 2, there are many instances where I cite sources such as stack exchange to show where I found code or learned about specific functions."
  },
  {
    "objectID": "reflection-template.html#il-1-adding-new-skills",
    "href": "reflection-template.html#il-1-adding-new-skills",
    "title": "Independent Learning (IL):",
    "section": "",
    "text": "I can find and adopt new packages to accomplish tasks.\nI can adapt to different syntax styles (tidy, base, formula style, data.table).\n\n\n\n\n\n\ni utilized ggrepel to annotate\nhttps://hersheyk.github.io/portfolio/posts/2025-05-01-Visualizations/visualizations.html#lab-2"
  },
  {
    "objectID": "reflection-template.html#il-2-online-resources",
    "href": "reflection-template.html#il-2-online-resources",
    "title": "Independent Learning (IL):",
    "section": "",
    "text": "I can use online resources (e.g., Google, ChatGPT, StackOverflow, YouTube) to solve problems, debug, or find new tools.\nI can use tutorials, etc. to enhance my understanding of new concepts.\nI can find source code for similar projects to use as starting points for my own.\n\n\n\n\n\n\nIn Lab 2, there are many instances where I cite sources such as stack exchange to show where I found code or learned about specific functions."
  },
  {
    "objectID": "reflection-template.html#rw-1-file-code-and-data-management",
    "href": "reflection-template.html#rw-1-file-code-and-data-management",
    "title": "Independent Learning (IL):",
    "section": "[RW-1] File, code, and data management:",
    "text": "[RW-1] File, code, and data management:\n\nI can use Git and GitHub to track my progress (creating repos, cloning, forking, pull requesting).\nI always use R Projects and the {here} package to organize my scripts, notebooks, data, and applications.\nI always use pull requests when collaborating with others.\n\n\nLevel: 2\n\n\nJustification:\nI consistently use RProjects to organize my work and have learned a great deal more about connecting Github to R. I am pretty good about committing my work to the repo after any major changes to my code. I have pull requested in the past, however, have yet to use pull requests in this class. knitr::include_graphics(“images/commit_history.jpg”)"
  },
  {
    "objectID": "reflection-template.html#rw-2-notebooks",
    "href": "reflection-template.html#rw-2-notebooks",
    "title": "Independent Learning (IL):",
    "section": "[RW-2] Notebooks:",
    "text": "[RW-2] Notebooks:\n\nI can use Quarto to produce a reproducible notebook and polished rendered documents\nI can use appropriate chunk options (echo, error, cache, etc.) to render my Quarto document quickly and cleanly.\n\n\nLevel: 3\n\n\nJustification:\nI have learned more about the various html options provided in quarto including YAML background colors, table of contents, code-folding and embedding resources. I also use code chunk options such as #| message: false to not output messages after specific code chunks(particularly useful in chunks where I call libraries or pull in data). I also label my code chunks, as seen below by {r calling data}"
  },
  {
    "objectID": "reflection-template.html#rw-3-code-style",
    "href": "reflection-template.html#rw-3-code-style",
    "title": "Independent Learning (IL):",
    "section": "[RW-3] Code style",
    "text": "[RW-3] Code style\n\nMy code is clear, readable, well-organized, and well-commented.\n\n\nLevel: 2\n\n\nJustification\nI would say that I am very thorough about labeling code chunks(particularly because it makes it easy when I get an error as R informs me of the code chunk by name). I also am good about citing when I find code elsewhere, however I am not great at keeping my code clean and well-commented. Definitely something to work towards.\nknitr::include_graphics(“images/labeledchunks.jpg”)"
  },
  {
    "objectID": "reflection-template.html#rw-summary",
    "href": "reflection-template.html#rw-summary",
    "title": "Independent Learning (IL):",
    "section": "RW Summary",
    "text": "RW Summary"
  },
  {
    "objectID": "reflection-template.html#tc-1-project-summaries",
    "href": "reflection-template.html#tc-1-project-summaries",
    "title": "Independent Learning (IL):",
    "section": "[TC-1] Project summaries:",
    "text": "[TC-1] Project summaries:\n\nI can create clear and succinct summaries of a project.\nI accurately interpret statistical or modeling results.\nI consider the appropriate scope and impact of my project results.\n\n\nLevel: 1\n\n\nJustification:\nI don’t believe I have done this at all yet"
  },
  {
    "objectID": "reflection-template.html#tc-2-documentation",
    "href": "reflection-template.html#tc-2-documentation",
    "title": "Independent Learning (IL):",
    "section": "[TC-2] Documentation:",
    "text": "[TC-2] Documentation:\n\nI can create a user-friendly dashboard.\nI provide ample documentation for my custom functions.\n\n\nLevel: 1\n\n\nJustification:\nI have made a dashboard as seen on shinyapps. I have not made any custom functions to document.\nhttps://ezd0m8-harshini-k.shinyapps.io/lab4/#belief-in-vaccine-safety-statistics"
  },
  {
    "objectID": "reflection-template.html#tc-summary",
    "href": "reflection-template.html#tc-summary",
    "title": "Independent Learning (IL):",
    "section": "TC Summary",
    "text": "TC Summary"
  },
  {
    "objectID": "reflection-template.html#dm-1-data-preparation",
    "href": "reflection-template.html#dm-1-data-preparation",
    "title": "Independent Learning (IL):",
    "section": "[DM-1] Data Preparation",
    "text": "[DM-1] Data Preparation\n\nI can read in datasets to R, including untidy ones.\nI can clean datasets to deal with missing data, typos, poor formatting, etc.\n\n\nLevel: 2\n\n\nJustification:\nI can read in data and I can pivot it and restructure the data as necessary to deal with formatting, as can be seen in Lab 2 where I restructure the however I do not believe I have had to deal with missing data or typos yet. I can read in different sheets of the same excel file."
  },
  {
    "objectID": "reflection-template.html#dm-2-data-wrangling",
    "href": "reflection-template.html#dm-2-data-wrangling",
    "title": "Independent Learning (IL):",
    "section": "[DM-2] Data Wrangling",
    "text": "[DM-2] Data Wrangling\n\nI can cleverly use pivoting, separating, grouping, and joining to wrangle data.\nI can use mapping (purrr) to perform repeated tasks.\n\n\nLevel: 2\n\n\nJustification:\nWhile I have not used purrr I have extensively pivoted and joined data to create visualizations that answer specific questions or replicate specific outcomes"
  },
  {
    "objectID": "reflection-template.html#dm-3-data-formats",
    "href": "reflection-template.html#dm-3-data-formats",
    "title": "Independent Learning (IL):",
    "section": "[DM-3] Data Formats",
    "text": "[DM-3] Data Formats\n\nI can use API urls to access JSON data and convert it into a data frame\nI can scrape data from the web and convert it into a data frame\n\n\n## Fill in the line below with your self-assigned level for this objective.\nmy_level &lt;- 1\n\nportfolio_levels &lt;- portfolio_levels %&gt;%\n  bind_rows(tibble(Objective = \"DM-3\", \n                   Level = my_level))\n\n\nLevel: 1\n\n\nJustification\nI have not done this in R or in this class but I have doen it elsewhere? Not sure if that is relevant."
  },
  {
    "objectID": "reflection-template.html#dm-summary",
    "href": "reflection-template.html#dm-summary",
    "title": "Independent Learning (IL):",
    "section": "DM Summary",
    "text": "DM Summary"
  },
  {
    "objectID": "reflection-template.html#pv-1-clear-accessible-visualizations",
    "href": "reflection-template.html#pv-1-clear-accessible-visualizations",
    "title": "Independent Learning (IL):",
    "section": "[PV-1] Clear & Accessible Visualizations",
    "text": "[PV-1] Clear & Accessible Visualizations\n\nI can make my plots more clear by removing the legend and adding annotations.\nI can edit the titles, subtitles, captions, axis labels, etc. to create a clearly labelled plot.\nI can choose colors (“scales”) and themes to make a visually pleasing and accessible plot.\n\n\nLevel: 2\n\n\nJustification:"
  },
  {
    "objectID": "reflection-template.html#pv-2-dynamic-visualizations",
    "href": "reflection-template.html#pv-2-dynamic-visualizations",
    "title": "Independent Learning (IL):",
    "section": "[PV-2] Dynamic Visualizations",
    "text": "[PV-2] Dynamic Visualizations\n\nI can use a package like {gganimate} to create self-contained gifs.\nI can use a package like {plotly}, {ggplotly}, {leaflet}, {ggirafe}, etc. to make interactive html widgets.\n\n\nLevel: 2\n\n\nJustification:\nI have not used gganimate to create a self-contained gif. I have, however used leaflet to make interactive widgets as seen on https://ezd0m8-harshini-k.shinyapps.io/lab4/#belief-in-vaccine-safety-statistics"
  },
  {
    "objectID": "reflection-template.html#pv-3-interactive-visualizations",
    "href": "reflection-template.html#pv-3-interactive-visualizations",
    "title": "Independent Learning (IL):",
    "section": "[PV-3] Interactive Visualizations",
    "text": "[PV-3] Interactive Visualizations\n\nI can use Shiny or webR to create visualizations that react to a user’s input.\n\n\nLevel: 2\n\n\nJustification:\nhttps://ezd0m8-harshini-k.shinyapps.io/lab4/#belief-in-vaccine-safety-statistics"
  },
  {
    "objectID": "reflection-template.html#pv-summary",
    "href": "reflection-template.html#pv-summary",
    "title": "Independent Learning (IL):",
    "section": "PV Summary",
    "text": "PV Summary"
  },
  {
    "objectID": "reflection-template.html#cdai-1-r-programming-language",
    "href": "reflection-template.html#cdai-1-r-programming-language",
    "title": "Independent Learning (IL):",
    "section": "[CDAI-1] R Programming Language",
    "text": "[CDAI-1] R Programming Language\n\nI understand non-standard evaluation (aka “tidy eval” or “unquoted objects”), and I can use tunneling in my functions.\nI understand functional programming, and I can use functions as objects in my code design.\n\n\nLevel: 1\n\n\nJustification:\nI have not done this yet"
  },
  {
    "objectID": "reflection-template.html#cdai-2-object-handling",
    "href": "reflection-template.html#cdai-2-object-handling",
    "title": "Independent Learning (IL):",
    "section": "[CDAI-2] Object Handling",
    "text": "[CDAI-2] Object Handling\n\nI have built in checks for possible input problems\nI can make reasonable choices in my code design about when to save intermediate objects.\nI can convert objects between types and structures as needed.\n\n\nLevel: 1\n\n\nJustification:\nI have not done this yet"
  },
  {
    "objectID": "reflection-template.html#cdai-3-speed-and-efficiency",
    "href": "reflection-template.html#cdai-3-speed-and-efficiency",
    "title": "Independent Learning (IL):",
    "section": "[CDAI-3] Speed and Efficiency",
    "text": "[CDAI-3] Speed and Efficiency\n\nI can recognize moments of possible slowdown in my code, and use built-in functions or parallelizing to speed them up.\nI always use and design vectorized functions whenever possible.\n\n\nLevel: 1\n\n\nJustification:\nI have not made any vectorized functions yet"
  },
  {
    "objectID": "reflection-template.html#cdai-4-supporting-functions",
    "href": "reflection-template.html#cdai-4-supporting-functions",
    "title": "Independent Learning (IL):",
    "section": "[CDAI-4] Supporting Functions",
    "text": "[CDAI-4] Supporting Functions\n\nI write helper / shortcut functions to streamline repeated tasks and make my code easier to read.\nI use intermediate functions to streamline repeated or looping processes.\n\n\nLevel: 1\n\n\nJustification:\nI have not made any shortcut functions yet"
  },
  {
    "objectID": "reflection-template.html#cdai-5-algorithmic-process",
    "href": "reflection-template.html#cdai-5-algorithmic-process",
    "title": "Independent Learning (IL):",
    "section": "[CDAI-5] Algorithmic Process",
    "text": "[CDAI-5] Algorithmic Process\n\nI can invent and implement my own iterative algorithm.\nMy loops are clean and efficient.\nI have built in checks for possible problems or extreme cases in the algorithm.\n\n\nLevel: 1\n\n\nJustification:\nI have not made an algorithms in this course yet."
  },
  {
    "objectID": "reflection-template.html#cdai-6-generative-art",
    "href": "reflection-template.html#cdai-6-generative-art",
    "title": "Independent Learning (IL):",
    "section": "[CDAI-6] Generative Art",
    "text": "[CDAI-6] Generative Art\n\nI can apply a variety of generative art functions to make a visually pleasing piece.\nI can explain why particular changes to the code result in particular differences in the visualization.\n\n\nLevel: 1\n\n\nJustification:\nI have not made any generative art yet."
  },
  {
    "objectID": "reflection-template.html#cdai-summary",
    "href": "reflection-template.html#cdai-summary",
    "title": "Independent Learning (IL):",
    "section": "CDAI Summary",
    "text": "CDAI Summary"
  },
  {
    "objectID": "reflection-template.html#grade",
    "href": "reflection-template.html#grade",
    "title": "Independent Learning (IL):",
    "section": "Grade",
    "text": "Grade\nBased on the summary plot above, I believe I have earned a ____ in STAT 541.\n\nJustification"
  },
  {
    "objectID": "posts/2025-05-12-dashboard-interactive/index.html",
    "href": "posts/2025-05-12-dashboard-interactive/index.html",
    "title": "Quarto Dashboards",
    "section": "",
    "text": "Link to static dashboard:\nhttps://hersheythegr8.quarto.pub/lab-3/#belief-in-vaccine-safety-statistics\nLink to interactive dashboard:\nhttps://ezd0m8-harshini-k.shinyapps.io/lab4/#belief-in-vaccine-safety-statistics"
  },
  {
    "objectID": "posts/2025-05-27-webscraping/index.html",
    "href": "posts/2025-05-27-webscraping/index.html",
    "title": "Webscrapinf",
    "section": "",
    "text": "Web-scraping"
  },
  {
    "objectID": "posts/2025-04-24-dashboard-static/index.html",
    "href": "posts/2025-04-24-dashboard-static/index.html",
    "title": "Static Quarto Dashboards",
    "section": "",
    "text": "I was very proud to get this lab up and working. I definitely learned a lot in the process. I believe a lot of what I learned in making static quarto dashboards was encapsulated in lab 4 with the interactive dashboards and lab 2, where I set up a lot of the initial data. As a result, I do not mention this lab too much in the final reflection. I believe the main standard this lab showcases is RW: 3 as I label all my code chunks and in value boxes, I use code-chunk options.\n\n\n\nlist(\n  value = toupper(lowest_country)\n)\n\n\nknitr::include_graphics(\"C:/Users/Geetha/OneDrive/Documents/STAT541/portfolio/images/labeledchunks.JPG\")\n\n\n\n\n\n\n\n\nYou can visit my published static dashboard below:\nhttps://hersheythegr8.quarto.pub/lab-3/#belief-in-vaccine-safety-statistics"
  },
  {
    "objectID": "posts/2025-04-14-Visualizations/visualizations.html",
    "href": "posts/2025-04-14-Visualizations/visualizations.html",
    "title": "Visualizations",
    "section": "",
    "text": "I found this lab to help me remember and sharpen my ggplot skills! I particularly feel I have showcased IL-1, IL2, DM-1, TC-1 and PV-1 as I utilized ggrepel to annotate a plot in lab 2 for visualizations, used a custom color palette, wrangled data, interpreted plots, and presented visuals well. You can see these outcomes highlighted in the floating table of contents, to help you visit each one!\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readxl)\nlibrary(ggrepel)\nlibrary(scales)\nlibrary(leaflet)\n\nlibrary(rnaturalearth)\nlibrary(sf)\nlibrary(rnaturalearthdata)\n\n\n\n\nWhile there are certainly issues with this image, do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\nI believe this plot is trying to show us the proportion of people in a particular country that believe a vaccine is safe. It shows us one observation per country where the y-axis appears to be country? It also sorted the observations by proportion, so that it appears that the proportions increase as the y-axis goes up.\n\nList the variables that appear to be displayed in this visualization. Hint: Variables refer to columns in the data.\n\nThe country, the global region of the country and the percentage of people in the country that believe a vaccine is safe.\n\nNow that you’re versed in the grammar of graphics (e.g., ggplot), list the aesthetics used and which variables are mapped to each.\n\nThe x-axis the percentage of people in the country that believe a vaccine is safe. The y-axis is the country, the color is filled by global region.\n\nWhat type of graph would you call this? Meaning, what geom would you use to produce this plot?\n\nI would call this a scatter plot and would use geom point to produce it.\n\nProvide at least four problems or changes that would improve this graph. Please format your changes as bullet points!\n\n\nI think this is a graph that is faceted by region of the world, but it lends to a strange stacked graph like view that is not very intuitive, and leaves some plots stranded from their axes. I would try faceting differently or trying to remove the facet entirely.\nI think having the y-axis be the countries is a bit strange, and that sorting it by the proportion feels odd, as though it is increasing over time or something, I would try sorting it alphabetically or removing the y-axis and making it a box-plot instead.\nI think having the legend at the bottom is unnecessary as the global region is also written directly onto each facet of the plot, so I would remove one of those, preferably the legend, depending on how my plot turns out.\nI think having to state that the dark vertical lines represent region medians but also not writing the number of each on the plot itself is confusing and forces the reader to then look for th median by finding the axis\n\n\n\n\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\ndata&lt;-read_excel(\"C:\\\\Users\\\\Geetha\\\\Downloads\\\\wgm2018-dataset-crosstabs-all-countries.xlsx\")\n\n\nnational &lt;- data[c('...1', '...2', '...3', 'National results','...5')]\ncolnames(national) &lt;- c(\"Country\", \"Question\", \"Response\", \"National_Results_Col_Per\", \"National_Results_Count\")\n\nnational &lt;- national[!(national$Country %in% c(NA, 'Country')),]\n#drop title row since renamed cols alr\n\n\nnational$QNumber &lt;- str_split_i(national$Question, \" \", 1)\n\n\nasia &lt;- c('Afghanistan', 'Bangladesh', 'Cambodia', 'China', 'India', 'Indonesia', 'Japan', 'Laos', 'Malaysia', 'Mongolia', 'Myanmar', 'Nepal', 'Pakistan', 'Philippines', 'Singapore', 'South Korea', 'Sri Lanka', 'Taiwan', 'Thailand', 'Vietnam'\n)\n\nmena &lt;- c('Algeria', 'Egypt', 'Iran', 'Iraq', 'Israel', 'Jordan', 'Kuwait', 'Lebanon','Libya', 'Morocco', 'Palestine', 'Saudi Arabia', 'Tunisia', 'United Arab Emirates', 'Yemen'\n)\n\namericas &lt;- c('Argentina', 'Bolivia', 'Brazil', 'Canada', 'Chile', 'Colombia', 'Costa Rica', 'Dominican Republic', 'Ecuador', 'El Salvador', 'Guatemala', \"Haiti\", 'Honduras','Mexico', 'Nicaragua', 'Panama', 'Paraguay', 'Peru', 'United States', 'Uruguay', 'Venezuela'\n)\n\nsub_sahara &lt;- c('Benin', 'Botswana', 'Burkina Faso', 'Burundi', 'Cameroon', 'Congo, Rep.','Comoros', 'Chad','Eswatini','Ethiopia', 'Gabon', 'Ghana', 'Guinea', 'Ivory Coast', 'Kenya', 'Liberia', 'Madagascar', 'Malawi', 'Mali', 'Mauritania', 'Mauritius','Mozambique', 'Namibia', 'Niger', 'Nigeria', 'Rwanda', 'Senegal','Sierra Leone', 'South Africa', 'Tanzania', 'The Gambia', 'Togo','Uganda', 'Zambia', 'Zimbabwe'\n)\n\neurope &lt;- c('Albania', 'Austria', 'Belgium', 'Bosnia and Herzegovina', 'Bulgaria','Croatia', 'Cyprus', 'Czech Republic', 'Denmark', 'Finland', 'France','Germany', 'Greece', 'Hungary', 'Iceland', 'Ireland', 'Italy', 'Kosovo','Luxembourg', 'Macedonia', 'Malta', 'Netherlands', 'Norway', \"Poland\", 'Northern Cyprus', 'Montenegro', 'Portugal', 'Romania', 'Serbia', 'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'Switzerland', 'Turkey', 'United Kingdom'\n)\n\nformer_soviet &lt;- c('Armenia', 'Azerbaijan', 'Belarus', 'Estonia', 'Georgia', 'Kazakhstan', 'Kyrgyzstan', 'Latvia', 'Lithuania', 'Moldova', 'Russia', 'Tajikistan', 'Ukraine', 'Uzbekistan', 'Turkmenistan'\n)\n\noceania &lt;- c('Australia', 'New Zealand')"
  },
  {
    "objectID": "posts/2025-04-14-Visualizations/visualizations.html#part-1",
    "href": "posts/2025-04-14-Visualizations/visualizations.html#part-1",
    "title": "Visualizations",
    "section": "",
    "text": "While there are certainly issues with this image, do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\nI believe this plot is trying to show us the proportion of people in a particular country that believe a vaccine is safe. It shows us one observation per country where the y-axis appears to be country? It also sorted the observations by proportion, so that it appears that the proportions increase as the y-axis goes up.\n\nList the variables that appear to be displayed in this visualization. Hint: Variables refer to columns in the data.\n\nThe country, the global region of the country and the percentage of people in the country that believe a vaccine is safe.\n\nNow that you’re versed in the grammar of graphics (e.g., ggplot), list the aesthetics used and which variables are mapped to each.\n\nThe x-axis the percentage of people in the country that believe a vaccine is safe. The y-axis is the country, the color is filled by global region.\n\nWhat type of graph would you call this? Meaning, what geom would you use to produce this plot?\n\nI would call this a scatter plot and would use geom point to produce it.\n\nProvide at least four problems or changes that would improve this graph. Please format your changes as bullet points!\n\n\nI think this is a graph that is faceted by region of the world, but it lends to a strange stacked graph like view that is not very intuitive, and leaves some plots stranded from their axes. I would try faceting differently or trying to remove the facet entirely.\nI think having the y-axis be the countries is a bit strange, and that sorting it by the proportion feels odd, as though it is increasing over time or something, I would try sorting it alphabetically or removing the y-axis and making it a box-plot instead.\nI think having the legend at the bottom is unnecessary as the global region is also written directly onto each facet of the plot, so I would remove one of those, preferably the legend, depending on how my plot turns out.\nI think having to state that the dark vertical lines represent region medians but also not writing the number of each on the plot itself is confusing and forces the reader to then look for th median by finding the axis"
  },
  {
    "objectID": "posts/2025-04-14-Visualizations/visualizations.html#improving-the-bad-visualization",
    "href": "posts/2025-04-14-Visualizations/visualizations.html#improving-the-bad-visualization",
    "title": "Visualizations",
    "section": "",
    "text": "Improve the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\ndata&lt;-read_excel(\"C:\\\\Users\\\\Geetha\\\\Downloads\\\\wgm2018-dataset-crosstabs-all-countries.xlsx\")\n\n\nnational &lt;- data[c('...1', '...2', '...3', 'National results','...5')]\ncolnames(national) &lt;- c(\"Country\", \"Question\", \"Response\", \"National_Results_Col_Per\", \"National_Results_Count\")\n\nnational &lt;- national[!(national$Country %in% c(NA, 'Country')),]\n#drop title row since renamed cols alr\n\n\nnational$QNumber &lt;- str_split_i(national$Question, \" \", 1)\n\n\nasia &lt;- c('Afghanistan', 'Bangladesh', 'Cambodia', 'China', 'India', 'Indonesia', 'Japan', 'Laos', 'Malaysia', 'Mongolia', 'Myanmar', 'Nepal', 'Pakistan', 'Philippines', 'Singapore', 'South Korea', 'Sri Lanka', 'Taiwan', 'Thailand', 'Vietnam'\n)\n\nmena &lt;- c('Algeria', 'Egypt', 'Iran', 'Iraq', 'Israel', 'Jordan', 'Kuwait', 'Lebanon','Libya', 'Morocco', 'Palestine', 'Saudi Arabia', 'Tunisia', 'United Arab Emirates', 'Yemen'\n)\n\namericas &lt;- c('Argentina', 'Bolivia', 'Brazil', 'Canada', 'Chile', 'Colombia', 'Costa Rica', 'Dominican Republic', 'Ecuador', 'El Salvador', 'Guatemala', \"Haiti\", 'Honduras','Mexico', 'Nicaragua', 'Panama', 'Paraguay', 'Peru', 'United States', 'Uruguay', 'Venezuela'\n)\n\nsub_sahara &lt;- c('Benin', 'Botswana', 'Burkina Faso', 'Burundi', 'Cameroon', 'Congo, Rep.','Comoros', 'Chad','Eswatini','Ethiopia', 'Gabon', 'Ghana', 'Guinea', 'Ivory Coast', 'Kenya', 'Liberia', 'Madagascar', 'Malawi', 'Mali', 'Mauritania', 'Mauritius','Mozambique', 'Namibia', 'Niger', 'Nigeria', 'Rwanda', 'Senegal','Sierra Leone', 'South Africa', 'Tanzania', 'The Gambia', 'Togo','Uganda', 'Zambia', 'Zimbabwe'\n)\n\neurope &lt;- c('Albania', 'Austria', 'Belgium', 'Bosnia and Herzegovina', 'Bulgaria','Croatia', 'Cyprus', 'Czech Republic', 'Denmark', 'Finland', 'France','Germany', 'Greece', 'Hungary', 'Iceland', 'Ireland', 'Italy', 'Kosovo','Luxembourg', 'Macedonia', 'Malta', 'Netherlands', 'Norway', \"Poland\", 'Northern Cyprus', 'Montenegro', 'Portugal', 'Romania', 'Serbia', 'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'Switzerland', 'Turkey', 'United Kingdom'\n)\n\nformer_soviet &lt;- c('Armenia', 'Azerbaijan', 'Belarus', 'Estonia', 'Georgia', 'Kazakhstan', 'Kyrgyzstan', 'Latvia', 'Lithuania', 'Moldova', 'Russia', 'Tajikistan', 'Ukraine', 'Uzbekistan', 'Turkmenistan'\n)\n\noceania &lt;- c('Australia', 'New Zealand')"
  },
  {
    "objectID": "posts/2025-04-14-Visualizations/visualizations.html#second-data-visualization-improvement",
    "href": "posts/2025-04-14-Visualizations/visualizations.html#second-data-visualization-improvement",
    "title": "Visualizations",
    "section": "Second Data Visualization Improvement",
    "text": "Second Data Visualization Improvement\n\nSelect a data visualization in the report that you think could be improved. Be sure to cite both the page number and figure title. Do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\nChart 5.7: Map of proportions of people reporting vaccinating their children on page 121. This graph is telling us what percentage of the people in a particular country say their children have been vaccinated. It compares between countries, highlighting where this percentage is particularly high or low.\n\n#knitr::include_graphics(\"images/Capture.jpg\")\n\n\nList the variables that appear to be displayed in this visualization.\n\nPercentage of people who answered ‘yes’ to their children having received vaccines and Country,\n\nNow that you’re versed in the grammar of graphics (ggplot), list the aesthetics used and which variables are specified for each.\n\nThe map shows the variable country, the color is filled by the percentage of people who answered ‘yes’.\n\nWhat type of graph would you call this?\n\nI would call this a chloropleth map!\nSource: https://support.esri.com/en-us/gis-dictionary/choropleth-map#:~:text=From%20the%20Greek%20terms%20choro,combining%20different%20sets%20of%20symbols.\n\nList all of the problems or things you would improve about this graph.\n\n\nI would make the color scaling more distinct and more apparent as it is difficult to visibly see the percentage or people who said their children had been vaccinated.\nI might add in global region to see if that shows any distinctions.\nI would make the countries that were not surveyed a more distinct color from the background color as it is hard to notice island nations and the like.\n\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\nnational2 &lt;- national |&gt;\n  fill(QNumber, .direction = \"down\") |&gt;\n  #Source for .direction: https://tidyr.tidyverse.org/reference/fill.html\n  filter(QNumber == \"Q28\")|&gt; filter(Response == \"Yes\") |&gt; mutate(Region = case_when(\n    \n    Country %in% asia ~ \"Asia\",\n    Country %in% mena ~ \"Middle East and North Africa\",\n    Country %in% americas ~ \"Americas\",\n     Country %in% sub_sahara ~ \"Sub-Saharan Africa\",\n    Country %in% europe ~ \"Europe\",\n    \n    Country %in% former_soviet ~ \"Former Soviet Union\",\n    \n    Country %in% oceania ~ \"Oceania\",\n    \n    TRUE ~ \"Other\" #used to check, there are none that fall in this category\n  ))\n\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nworld$Country &lt;- tolower(world$name_long)\nnational2$Country &lt;- tolower(national2$Country)\n\nworld_data &lt;- left_join(world, national2, by = c(\"Country\" = \"Country\"))\nworld_data$National_Results_Col_Per &lt;- as.numeric(world_data$National_Results_Col_Per)\n\n#world_data$National_Results_Col_Per[is.na(world_data$National_Results_Col_Per )] &lt;- \"Countries not surveyed\"\n\n\n#colorpalette\npal &lt;- colorBin(\n  palette =c(\"#ffffd4\", \"#fec44f\", \"#fe9929\", \"#fc4e2a\", \"#b10026\"),\n  #https://loading.io/color/feature/YlOrRd-8\n  domain = world_data$National_Results_Col_Per,\n  bins =c(0, 0.70, 0.80, 0.90, 0.95, 1.00), na.color =\"#d3d3d3\"  \n)\n\n#plot\nleaflet(world_data) |&gt; addTiles() |&gt;\n  addPolygons(\n    fillColor = ~pal(National_Results_Col_Per), weight = 1,\n    color = \"white\", fillOpacity = 0.8,\n    label = ~paste0(Country, \": \", National_Results_Col_Per, \"%\"),\n    highlight = highlightOptions(\n      weight = 2, color = \"#666\",\n      fillOpacity = 0.9, bringToFront = TRUE\n    )\n    #Source: https://r-charts.com/spatial/interactive-maps-leaflet/\n  ) |&gt;\n  \n  addLegend(\n    pal = pal, values = ~National_Results_Col_Per,\n    title = \"Percentage of people who say  &lt;br&gt; their child has been vaccinated\", position = \"bottomright\"\n    #Source line break: https://www.reddit.com/r/Rlanguage/comments/6bsji1/add_line_break_to_leaflet_pop_up/\n  )"
  },
  {
    "objectID": "posts/2025-04-14-Visualizations/visualizations.html#third-data-visualization-improvement",
    "href": "posts/2025-04-14-Visualizations/visualizations.html#third-data-visualization-improvement",
    "title": "Visualizations",
    "section": "Third Data Visualization Improvement",
    "text": "Third Data Visualization Improvement\n\nSelect a data visualization in the report that you think could be improved. Be sure to cite both the page number and figure title. Do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?\n\n\n\n\nList the variables that appear to be displayed in this visualization.\n\nThe percentages for all of the following columns: Men, Women, 15-29, 30-49,50+, Elementary education or less, Secondary education, Post-secondary education, Rural/small town, Big city/suburb,  as well as separate created onee like Parents and Non-Parents\n\nNow that you’re versed in the grammar of graphics (ggplot), list the aesthetics used and which variables are specified for each.\n\nThe x axis is the demographic group while the y-axis is the percentage of the group that believes vaccines are unsafe!\n\nWhat type of graph would you call this?\n\nA bar plot!\n\nList all of the problems or things you would improve about this graph.\n\nI would facet this better and change the background color as the yellow almost blends in with the lighter blue background.\n\nImprove the visualization above by either re-creating it with the issues you identified fixed OR by creating a new visualization that you believe tells the same story better.\n\n\nnational3 &lt;- data[c('...1', '...2','...3','National results','...5',\n                    'Gender','...7', '...8', '...9',\n                     'Age Cohort','...11', '...12',\n                    '...13', '...14', '...15', 'General Educational Background', \n                  '...17','...18', '...19', \n                    '...20','...21','Area Type', \n                  '...23', '...24','...25')]\n\ncolnames(national3)&lt;- c(\"Country\", \"Question\", \"Response\",\n                         \"National_Results_Col_Per\", \"National_Results_Count\",\n                         \"Men\", \"Man_num\", \"Women\", \"Woman_num\",\n                         \"15-29\", \"15_29_Num\",\"30-49\",\n                 \"30_49_Num\", \"50+\", \"Above_50_Num\",\n                         \"Elementary education or less\", \"elementary_num\",\n                         \"Secondary education\",\"secondary_num\", \n                         \"Post-secondary education\",\"college_num\", \n                         \"Rural/small town\",\"rural_num\", \n                         \"Big city/suburb\",\"suburb_num\")\n\nnational3 &lt;- national3[!(national3$Country %in% c(NA, 'Country')),]\nnational3$QNumber &lt;- str_split_i(national3$Question, \" \", 1)\n\nnational3 &lt;- national3 |&gt; \n  filter(Country == \"France\")|&gt; fill(QNumber, .direction = \"down\") |&gt;\n  filter(QNumber == \"Q25\")|&gt; filter(Response %in% c(\"Strongly disagree\",\"Somewhat disagree\")) |&gt;\n  mutate(across(c(National_Results_Col_Per, Men, Women, `15-29`, `30-49`,`50+`, \n                  `Elementary education or less`, `Secondary education`, `Post-secondary education`,\n                  `Rural/small town`, `Big city/suburb`),as.numeric)) |&gt;\n  \n  summarize(across(c(National_Results_Col_Per,Men, Women, `15-29`, `30-49`,`50+`, \n                  `Elementary education or less`, `Secondary education`, `Post-secondary education`,\n                  `Rural/small town`, `Big city/suburb`), sum, na.rm = TRUE), .groups = \"drop\")|&gt;\n  mutate(Country = \"France\")\n\nWarning: There was 1 warning in `summarize()`.\nℹ In argument: `across(...)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n\ndata2&lt;-read_excel(\"C:\\\\Users\\\\Geetha\\\\Downloads\\\\wgm2018-dataset-crosstabs-all-countries.xlsx\", sheet = \"Full dataset\")\n\n\n# France's WP5 is 13\nfrance&lt;- data2|&gt; filter( WP5 == 13) |&gt; select(WP5, Q25, Q27)|&gt;group_by(Q27, Q25) |&gt;\n  summarise(count = n(), .groups = \"drop_last\") |&gt;\n  mutate(percentage = round(count / sum(count), 6)) |&gt; ungroup() |&gt;\n  filter(Q25 %in% c(4, 5)) |&gt; group_by(Q27) |&gt;\n  summarise( total_count = sum(count),\n             total_percentage = sum(percentage)) |&gt; pivot_wider(\n    names_from = Q27,\n    values_from = c(total_count, total_percentage),\n    names_glue = \"Q27_{Q27}_{.value}\") |&gt; select(Q27_1_total_percentage, Q27_2_total_percentage) |&gt;mutate(Country = \"France\")\n\n\ncolnames(france) &lt;- c(\"Parents\", \"Non-Parents\", \"Country\")\n\n\nfrance_all&lt;- merge(national3, france, by = \"Country\")"
  },
  {
    "objectID": "posts/2025-04-28-dashboard-interactive/index.html",
    "href": "posts/2025-04-28-dashboard-interactive/index.html",
    "title": "Interactive Quarto Dashboards",
    "section": "",
    "text": "Link to interactive dashboard:\nhttps://ezd0m8-harshini-k.shinyapps.io/lab4/#belief-in-vaccine-safety-statistics"
  },
  {
    "objectID": "posts/2025-05-19-JSON-and-APIS/index.html",
    "href": "posts/2025-05-19-JSON-and-APIS/index.html",
    "title": "JSON and APIs",
    "section": "",
    "text": "library(httr)\nlibrary(jsonlite)\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(leaflet)\nlibrary(knitr)\nlibrary(tidyjson)\n#eab39c3c6fb6d4f959dbcb4ad3ad9a8205551bc1\n\n\ncapitals_names &lt;- read_lines(\"https://people.sc.fsu.edu/~jburkardt/datasets/states/state_capitals_name.txt\")\ncapitals_lat_long &lt;- read_lines(\"https://people.sc.fsu.edu/~jburkardt/datasets/states/state_capitals_ll.txt\")\n\n\nlatlon_df &lt;- str_split(capitals_lat_long, \"\\\\s+\", simplify = TRUE) |&gt;  \n  as.data.frame() |&gt; \n  rename(state = V1, latitude = V2, longitude = V3) |&gt; \n  mutate(state = trimws(state))\n\ncapitals_df &lt;- str_split(capitals_names, '\"', simplify = TRUE) |&gt;  \n  as.data.frame() |&gt; \n  rename(state = V1, capital = V2) |&gt; \n  select(-V3) |&gt; \n  mutate(state = trimws(state))\n\nfull_capitals_dataset &lt;- full_join(latlon_df, capitals_df, by = \"state\")\n\n\nfull_capitals_dataset &lt;- full_capitals_dataset |&gt; \n  mutate(\n    capital = str_remove_all(capital, '\"'),\n    latitude = as.numeric(latitude),\n    longitude = as.numeric(longitude)\n  )\n\n\nresponse &lt;- GET(\"https://api.g7vrd.co.uk/v1/satellite-passes/25544/51.45/-2.5833.json\")\n\nspace &lt;- response$content |&gt; \n  rawToChar() |&gt;  \n  fromJSON()\n\nstr(space)\n\nList of 11\n $ api_status        : chr \"ALPHA\"\n $ request_timestamp : chr \"2025-06-09T16:43:59.782392226Z\"\n $ norad_id          : int 25544\n $ satellite_name    : chr \"ISS\"\n $ tle_last_retrieved: chr \"2025-06-08T21:52:58.294612771Z\"\n $ lat               : num 51.5\n $ lon               : num -2.58\n $ hours             : int 48\n $ min_elevation     : int 30\n $ query_ms          : int 15\n $ passes            :'data.frame': 6 obs. of  6 variables:\n  ..$ start        : chr [1:6] \"2025-06-10T10:34:29.767Z\" \"2025-06-10T12:11:14.767Z\" \"2025-06-10T13:47:59.767Z\" \"2025-06-11T09:46:04.767Z\" ...\n  ..$ tca          : chr [1:6] \"2025-06-10T10:39:59.767Z\" \"2025-06-10T12:16:44.767Z\" \"2025-06-10T13:52:59.767Z\" \"2025-06-11T09:51:34.767Z\" ...\n  ..$ end          : chr [1:6] \"2025-06-10T10:45:24.767Z\" \"2025-06-10T12:22:09.767Z\" \"2025-06-10T13:58:34.767Z\" \"2025-06-11T09:56:54.767Z\" ...\n  ..$ aos_azimuth  : int [1:6] 256 277 283 248 273 283\n  ..$ los_azimuth  : int [1:6] 80 100 131 78 93 122\n  ..$ max_elevation: num [1:6] 80 86 35 67 84 48\n\njson_tbl &lt;- response$content |&gt; \n  rawToChar() |&gt; \n  as.tbl_json()\n\njson_tbl |&gt;  \n  spread_all() |&gt; \n  enter_object(\"passes\") |&gt; \n  gather_array() |&gt;     # if it's a JSON array\n  spread_all() |&gt; \n  select(start)\n\n# A tbl_json: 6 x 2 tibble with a \"JSON\" attribute\n  ..JSON                  start                   \n  &lt;chr&gt;                   &lt;chr&gt;                   \n1 \"{\\\"start\\\":\\\"2025-...\" 2025-06-10T10:34:29.767Z\n2 \"{\\\"start\\\":\\\"2025-...\" 2025-06-10T12:11:14.767Z\n3 \"{\\\"start\\\":\\\"2025-...\" 2025-06-10T13:47:59.767Z\n4 \"{\\\"start\\\":\\\"2025-...\" 2025-06-11T09:46:04.767Z\n5 \"{\\\"start\\\":\\\"2025-...\" 2025-06-11T11:22:44.767Z\n6 \"{\\\"start\\\":\\\"2025-...\" 2025-06-11T12:59:29.767Z\n\n\n\nget_pass_times &lt;- function(lat, lon) {\n  #Construct the API URL for the given latitude and longitude\n  url &lt;- paste0(\"https://api.g7vrd.co.uk/v1/satellite-passes/25544/\", lat, \"/\", lon, \".json\")\n  response &lt;- GET(url) #Call the API \n\n  if (status_code(response) == 200) {\n    data &lt;- fromJSON(rawToChar(response$content)) #Convert raw JSON to useable form\n    \n    if (!is.null(data$passes)) {\n      return(head(data$passes$tca, 3)) #If passes exists in the data, extract first three pass times. Note that these are ordered descending, so it should get the earliest three times.\n    }\n  }\n\n  return(rep(NA, 3))  #Return 3 NAs if unavailable\n}\n\n\ncapitals_all_passes &lt;- full_capitals_dataset |&gt; \n  mutate(pass_times = pmap(list(latitude, longitude), get_pass_times))\n\ncapitals_with_passes &lt;- capitals_all_passes |&gt; \n  mutate(\n    pass_time_1 = map_chr(pass_times, ~ if(length(.) &gt;= 1) .[1] else NA), \n    pass_time_2 = map_chr(pass_times, ~ if(length(.) &gt;= 2) .[2] else NA),\n    pass_time_3 = map_chr(pass_times, ~ if(length(.) &gt;= 3) .[3] else NA)) |&gt;\n  select(-pass_times) |&gt;\n  filter(!state %in% c('US', 'PR'))\n  #There were two Districts of Columbia in the dataset, one with the wrong latitude, so we dropped the other DC and San Juan of Puerto Rico(not sure why this was showing up).\n\n\ncapitals_with_passes &lt;- capitals_with_passes %&gt;%\n  arrange(is.na(pass_time_1), pass_time_1) %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    pop_up_html = if (is.na(pass_time_1)) {\n      paste0(\"&lt;b&gt;\", capital, \"&lt;/b&gt;&lt;br/&gt;\",\n             \"ISS will not pass over this location in the next 72 hours\")\n    } else {\n      paste0(\"&lt;b&gt;\", toupper(capital), \"&lt;/b&gt;&lt;br/&gt;\",\n             \"Next Three ISS Passtimes:&lt;br/&gt;\",\n             # read way many articles much about date time formatting and functions, but so happy with how it looks now\n             # https://learn.microsoft.com/en-us/dotnet/standard/base-types/standard-date-and-time-format-strings\n             format(as_datetime(pass_time_1), \"%B %d, %Y  %I:%M %p %Z\"),\n             \"&lt;br/&gt;\",\n             if_else(!is.na(pass_time_2),\n                     (format(as_datetime(pass_time_2), \"%B %d, %Y  %I:%M %p %Z\")),\n                     \"No second pass\"),\n             \"&lt;br/&gt;\",\n             if_else(!is.na(pass_time_3), (format(as_datetime(pass_time_3), \"%B %d, %Y  %I:%M %p %Z\")), \n                     \"No third pass\"))\n    },  \n    \n    label_html = htmltools::HTML((paste0(\n      \"&lt;b&gt;\", toupper(capital), \"&lt;b&gt;&lt;br/&gt;\",\n      if_else(is.na(pass_time_1),\n              \"ISS will not pass over this location in the next 72 hours\",\n              paste(\"Next ISS Passtime:\",\n                    format(as_datetime(pass_time_1), \"%B %d, %Y  %I:%M %p %Z\"))\n     ))))\n  ) %&gt;%\n  ungroup()\n\n# created new columns in the dataframe, because the html options were having issues running within the leaflet plot and to make the code for the plot cleaner\n\n\n#dropping NAs from the path\ncaps&lt;- capitals_with_passes|&gt; filter(!is.na(pass_time_1))\n\n\niss_icon &lt;- icons(\n  iconUrl = here::here(\"pngtree-space-station-probe-icon-png-image_4687961.png\"), \n  iconWidth = 30, \n  iconHeight = 30\n)\n\nleaflet(capitals_with_passes) |&gt; addTiles() %&gt;%\n  addMarkers(lng = ~longitude,\n             lat = ~latitude,\n             icon = iss_icon,\n             label = ~label_html,\n             popup = ~pop_up_html\n            # so excited to have discovered the use of the tilda('~')\n             ) |&gt;\n  addPolylines(lng = caps$longitude,\n               lat = caps$latitude)"
  },
  {
    "objectID": "posts/2025-06-02-generative-art/index.html",
    "href": "posts/2025-06-02-generative-art/index.html",
    "title": "Generative Art",
    "section": "",
    "text": "library(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggforce)\nlibrary(ambient)\nlibrary(MetBrewer)\nlibrary(metR)      \nlibrary(scales)  \nlibrary(colorspace)\n\n\niris_art &lt;- function(data = iris) {\n  \n  dat &lt;- data %&gt;%\n    #transform iris data into something that is plottable polarly\n    mutate(\n      x0 = (Sepal.Length - min(Sepal.Length)) / (max(Sepal.Length) - min(Sepal.Length)),\n      y0 = (Sepal.Width - min(Sepal.Width)) / (max(Sepal.Width) - min(Sepal.Width)),\n      x1 = x0 + (Petal.Length - min(Petal.Length)) / (max(Petal.Length) - min(Petal.Length)) * 0.3,\n      y1 = y0 + (Petal.Width - min(Petal.Width)) / (max(Petal.Width) - min(Petal.Width)) * 0.3,\n      size = Sepal.Length / max(Sepal.Length)\n    )\n  # green palette\n  paquin_pal &lt;- met.brewer(\"Veronese\")[1:3]  \n  \n  ggplot(dat, aes(x = x0, y = y0, xend = x1, yend = y1, colour = Species, size = size)) +\n    geom_segment(lineend = \"round\", show.legend = FALSE) +\n    coord_polar() +\n    scale_colour_manual(values = paquin_pal) +\n    scale_size(range = c(0.5, 3)) +\n    theme_void()+\n    theme(plot.background = element_rect(fill = \"beige\", color = NA))\n}\n\niris_art()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nTitle: Twist of Iris\nAt first glance, Twist of Iris feels like a a flower frozen mid-spin, caught in the act of opening. But stare a little longer, and the lines start to echo something else, an iris of an eye.\nThis piece takes the iris dataset, with each segment built from sepal and petal measurements, “twists” into movement and direction. The use of the a green palette lends the composition a natural, organic feel, like petals dancing in sunlight, pollen drifting in the wind, or a person’s eye. It plays with both meanings of “iris”(a flower and an eye ).\n\n# generate each individual polygon\ngenerate_polygon &lt;- function(center_x, center_y, radius, n_points) {\n  angles &lt;- seq(0, 2 * pi, length.out = n_points + 1)[-1]\n  angles &lt;- jitter(angles, amount = 0.2)\n  data.frame(\n    x = center_x + radius * cos(angles),\n    y = center_y + radius * sin(angles)\n  )\n}\n\npalette &lt;- met.brewer(\"Ingres\", n = 9, type = \"continuous\")\n# blue gold palette\n\nset.seed(42)\nn_polygons &lt;- 300\npolygon_data &lt;- bind_rows(lapply(1:n_polygons, function(i) {\n  center_x &lt;- runif(1, -10, 10)\n  center_y &lt;- runif(1, -10, 10)\n  radius &lt;- runif(1, 0.2, 0.4) # shape size\n  n_points &lt;- sample(3:7, 1)\n  base_color &lt;- sample(palette, 1)\n  \n  polygon &lt;- generate_polygon(center_x, center_y, radius, n_points)\n  polygon$group &lt;- i\n  polygon$fill &lt;- base_color\n  polygon\n}))\n\nggplot(polygon_data, aes(x = x, y = y, group = group, fill = fill)) +\n  # added an edge line to the shapes\n  geom_shape(alpha = 0.8, radius = unit(0.1, 'cm'), color = \"#736545\", size = 0.1) +\n  coord_equal() +\n  theme_void() +\n  scale_fill_identity() +\n  theme(plot.background = element_rect(fill = \"black\", color = NA))\n\n\n\n\n\n\n\n\nTitle: Isolated Pebbles\nDescription:\nIsolated Pebbles presents scattered stones, each rendered in earthy tones with a stark black void-like background. The colors of the stones suggests they are grounded and along with the irregularity of shape reminds the viewer of pebbles one might find on a riverside. These anchor each shape firmly against the deep black background, suggesting they rest quietly on unseen soil.\nWhile some pebbles appear clustered, almost friends, a second look reveals that none truly touch. Even shapes that share similar colors and forms(as with traits that people have in common) remain separated by subtle distances, and are not groped together, suggesting an inherent solitude. This conveys how closeness does not always equate to connection, and similarity does not guarantee friendship. This also could suggest that there are many people like you out there you might yet to have find them though!"
  },
  {
    "objectID": "posts/2025-04-14-Visualizations/visualizations.html#part-two-broad-visualization-improvement",
    "href": "posts/2025-04-14-Visualizations/visualizations.html#part-two-broad-visualization-improvement",
    "title": "Visualizations",
    "section": "Part Two: Broad Visualization Improvement",
    "text": "Part Two: Broad Visualization Improvement\n\nSecond Data Visualization Improvement\n\nSelect a data visualization in the report that you think could be improved. Be sure to cite both the page number and figure title. Do your best to tell the story of this graph in words. That is, what is this graph telling you? What do you think the authors meant to convey with it?"
  },
  {
    "objectID": "posts/2025-04-24-dashboard-static/index.html#rw-3",
    "href": "posts/2025-04-24-dashboard-static/index.html#rw-3",
    "title": "Static Quarto Dashboards",
    "section": "",
    "text": "list(\n  value = toupper(lowest_country)\n)\n\n\nknitr::include_graphics(\"C:/Users/Geetha/OneDrive/Documents/STAT541/portfolio/images/labeledchunks.JPG\")\n\n\n\n\n\n\n\n\nYou can visit my published static dashboard below:\nhttps://hersheythegr8.quarto.pub/lab-3/#belief-in-vaccine-safety-statistics"
  },
  {
    "objectID": "posts/2025-05-12-writing-efficient-functions/index.html",
    "href": "posts/2025-05-12-writing-efficient-functions/index.html",
    "title": "Writing Efficient Functions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dplyr)\ndiamonds&lt;- ggplot2::diamonds\nflights&lt;- nycflights13::flights\n\n\n\nWrite a function that removes outliers in a dataset. The user should be able to supply the dataset, the variables to remove outliers from, and a threshold on the number of SDs away from the mean used to define outliers.\nHint 1: You will need to calculate a z-score to filter the values! \nHint 2: You might want to consider specifying a default value (e.g., 3) for sd_thresh.\n\nremove_outliers&lt;- function(data, ... , sd_threshold = 3){\n  \n  variables &lt;- as.character(substitute(list(...)))[-1]\n  \n  keep &lt;- rep(TRUE, nrow(data))\n  # dataframe of values to keep\n  \n  for(each in variables){\n    if (!is.numeric(data[[each]])) {\n      warning(paste(\"Variable\", each\n                 , \"is not numeric! Only numeric variables are supported! We cannot drop outliers from this column\"))\n      next\n      # returns error for non-numeric variables\n    }\n    \n    mu &lt;- mean(data[[each]])\n    sd &lt;- sd(data[[each]])\n    z_scores &lt;- (data[[each]] - mu) / sd\n    # find the zscore of each instance of each variable\n    \n    keep &lt;- keep & abs(z_scores) &lt; sd_threshold\n    # filters out values where the zscore is greater than the specified threshold\n      }\n  return (data[keep, ])\n\n  \n}\n\n# [[]] vs [] https://stackoverflow.com/questions/1169456/the-difference-between-bracket-and-double-bracket-for-accessing-the-el\n\nThis function is not the most efficient as it does use a for loop.\n\n\n\n## Testing how your function handles multiple input variables\n\nremove_outliers(diamonds, \n                price, \n                x, \n                y, \n                z)\n\n# A tibble: 52,689 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 52,679 more rows\n\n\n\n## Testing how your function handles an input that isn't numeric\nremove_outliers(diamonds, \n                price, \n                color)\n\nWarning in remove_outliers(diamonds, price, color): Variable color is not\nnumeric! Only numeric variables are supported! We cannot drop outliers from\nthis column\n\n\n# A tibble: 52,734 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 52,724 more rows\n\n\n\n## Testing how your function handles a non-default sd_thresh\nremove_outliers(diamonds, \n                price,\n                x, \n                y, \n                z, \n                sd_threshold = 2)\n\n# A tibble: 50,099 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 50,089 more rows\n\n\n\n\n\n\nWrite a function that imputes missing values for numeric variables in a dataset. The user should be able to supply the dataset, the variables to impute values for, and a function to use when imputing. Hint 1: You will need to use across() to apply your function, since the user can input multiple variables. Hint 2: The replace_na() function is helpful here!\n\nimpute_missing &lt;- function( data, ..., func = sum){\n  # capture variable names\n  variables &lt;- as.character(substitute(list(...)))[-1]\n  \n   #issues a warning for non-numeric variables and retains them in the dataset without imputing\n  numeric_variables &lt;- variables[sapply(variables, function(x) is.numeric(data[[x]]))]\n  \n  non_numeric_vars &lt;- setdiff(variables, numeric_variables)\n  \n  if(length(non_numeric_vars) &gt; 0) {\n    warning(paste(\"The following variables are non-numeric and will not be imputed:\", paste(non_numeric_vars, collapse = \", \")))\n  }\n  \n  data |&gt;\n    mutate(across(\n      .cols = all_of(numeric_variables),\n      .fns = ~ replace_na(.x, func(.x, na.rm = TRUE))\n    ))\n}\n\nThis function is more efficient than the last one as it uses sapply() and the usage of dplyr makes this function more efficient than the last one.\n\n\n\n## Testing how your function handles multiple input variables\nimpute_missing(flights, \n               arr_delay, \n               dep_delay) \n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n## Testing how your function handles an input that isn't numeric\nimpute_missing(flights, \n               arr_delay, \n               carrier)\n\nWarning in impute_missing(flights, arr_delay, carrier): The following variables\nare non-numeric and will not be imputed: carrier\n\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n## Testing how your function handles a non-default impute_fun\nimpute_missing(flights, \n               arr_delay, \n               dep_delay, \n               func = median)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n\n\n\nWrite a fit_model() function that fits a specified linear regression model for a specified dataset. The function should:\n\nallow the user to specify if outliers should be removed (TRUE or FALSE)\nallow the user to specify if missing observations should be imputed (TRUE or FALSE)\n\nIf either option is TRUE, your function should call your remove_outliers() or impute_missing() functions to modify the data before the regression model is fit.\n\nfit_model &lt;- function(data, mod_formula, remove_outliers = FALSE, impute_missing = FALSE, ...) {\n  \n  #run helper functions if indicated\n  if (remove_outliers) {\n    data &lt;- remove_outliers(data, ...)\n  }\n  \n  if (impute_missing) {\n    data &lt;- impute_missing(data, ...)\n  }\n  \n  #fit the linear regression model\n  model &lt;- lm(mod_formula, data = data)\n  \n  # Return the fitted model\n  return(model)\n}\n\n\n\n\nfit_model(\n  diamonds,\n  mod_formula = price ~ carat + cut,\n  remove_outliers = TRUE,\n  impute_missing = TRUE,\n  price, \n  carat\n)\n\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2460.16      7526.96      1059.65      -410.54       295.80        82.62  \n\n\n\n\n\nIn the diamonds dataset, we want to understand the relationship between price and size (carat). We want to explore variation along two choices:\n\nThe variables included in the model. We’ll explore 3 sets of variables:\n\nNo further variables (just price and carat)\nAdjusting for cut\nAdjusting for cut and clarity\nAdjusting for cut, clarity, and color\n\nWhether or not to impute missing values\nWhether or not to remove outliers in the carat variable (we’ll define outliers as cases whose carat is over 3 SDs away from the mean).\n\n\n\n\n\nFirst, we need to define the set of parameters we want to iterate the fit_model() function over. The tidyr package has a useful function called crossing() that is useful for generating argument combinations. For each argument, we specify all possible values for that argument and crossing() generates all combinations. Note that you can create a list of formula objects in R with c(y ~ x1, y ~ x1 + x2).\n\ndf_arg_combos &lt;- crossing(\n    impute = c(TRUE, FALSE),\n    remove_outliers = c(TRUE, FALSE), \n    mod = c(y ~ x1, \n            y ~ x1 + x2)\n)\ndf_arg_combos\n\n# A tibble: 8 × 3\n  impute remove_outliers mod      \n  &lt;lgl&gt;  &lt;lgl&gt;           &lt;list&gt;   \n1 FALSE  FALSE           &lt;formula&gt;\n2 FALSE  FALSE           &lt;formula&gt;\n3 FALSE  TRUE            &lt;formula&gt;\n4 FALSE  TRUE            &lt;formula&gt;\n5 TRUE   FALSE           &lt;formula&gt;\n6 TRUE   FALSE           &lt;formula&gt;\n7 TRUE   TRUE            &lt;formula&gt;\n8 TRUE   TRUE            &lt;formula&gt;\n\n\nUse crossing() to create the data frame of argument combinations for our analyses.\n\nparam_sets &lt;- crossing(\n  impute = c(TRUE, FALSE),                           \n  remove_outliers = c(TRUE, FALSE),                   \n  mod = c(                                        \n    price ~ carat,   # No adjustment    \n    \n    price ~ carat + cut,                             \n    price ~ carat + cut + clarity,     \n    \n    # Adjusting for cut, clarity, and color\n    price ~ carat + cut + clarity + color            \n  )\n)\nparam_sets\n\n# A tibble: 16 × 3\n   impute remove_outliers mod      \n   &lt;lgl&gt;  &lt;lgl&gt;           &lt;list&gt;   \n 1 FALSE  FALSE           &lt;formula&gt;\n 2 FALSE  FALSE           &lt;formula&gt;\n 3 FALSE  FALSE           &lt;formula&gt;\n 4 FALSE  FALSE           &lt;formula&gt;\n 5 FALSE  TRUE            &lt;formula&gt;\n 6 FALSE  TRUE            &lt;formula&gt;\n 7 FALSE  TRUE            &lt;formula&gt;\n 8 FALSE  TRUE            &lt;formula&gt;\n 9 TRUE   FALSE           &lt;formula&gt;\n10 TRUE   FALSE           &lt;formula&gt;\n11 TRUE   FALSE           &lt;formula&gt;\n12 TRUE   FALSE           &lt;formula&gt;\n13 TRUE   TRUE            &lt;formula&gt;\n14 TRUE   TRUE            &lt;formula&gt;\n15 TRUE   TRUE            &lt;formula&gt;\n16 TRUE   TRUE            &lt;formula&gt;\n\n\n\n\n\nUse pmap() from purrr to apply the fit_model() function to every combination of arguments from diamonds.\n\nparam_sets&lt;-param_sets |&gt;\n  mutate(model = pmap(list(impute, remove_outliers, mod), \n                      function(impute, remove_outliers, mod) {\n                        fit_model(\n                          data = diamonds,\n                          mod_formula = mod,\n                          remove_outliers = remove_outliers,\n                          impute_missing = impute,\n                          price,\n                          carat\n                          # variable to use for outlier removal and imputation\n                          # variables cut, clarity and color are non-numeric\n                        )\n                      }))\n\n\nprint(param_sets$model)\n\n[[1]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat  \n      -2256         7756  \n\n\n[[2]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2701.38      7871.08      1239.80      -528.60       367.91        74.59  \n\n\n[[3]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3187.540     8472.026      713.804     -334.503      188.482        1.663  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4011.681    -1821.922      917.658     -430.047      257.141       26.909  \n  clarity^7  \n    186.742  \n\n\n[[4]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3710.603     8886.129      698.907     -327.686      180.565       -1.207  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4217.535    -1832.406      923.273     -361.995      216.616        2.105  \n  clarity^7      color.L      color.Q      color.C      color^4      color^5  \n    110.340    -1910.288     -627.954     -171.960       21.678      -85.943  \n    color^6  \n    -49.986  \n\n\n[[5]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat  \n      -2067         7411  \n\n\n[[6]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2460.16      7526.96      1059.65      -410.54       295.80        82.62  \n\n\n[[7]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2897.60      8118.13       618.65      -268.13       148.57         8.10  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n    3463.17     -1505.52       609.45      -286.81       158.48        71.83  \n  clarity^7  \n     183.33  \n\n\n[[8]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3376.856     8513.377      607.668     -263.835      142.453        5.506  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   3654.785    -1503.171      612.049     -225.568      124.920       47.356  \n  clarity^7      color.L      color.Q      color.C      color^4      color^5  \n    112.889    -1714.316     -539.239     -127.282       43.649      -60.866  \n    color^6  \n    -49.333  \n\n\n[[9]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat  \n      -2256         7756  \n\n\n[[10]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2701.38      7871.08      1239.80      -528.60       367.91        74.59  \n\n\n[[11]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3187.540     8472.026      713.804     -334.503      188.482        1.663  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4011.681    -1821.922      917.658     -430.047      257.141       26.909  \n  clarity^7  \n    186.742  \n\n\n[[12]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3710.603     8886.129      698.907     -327.686      180.565       -1.207  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4217.535    -1832.406      923.273     -361.995      216.616        2.105  \n  clarity^7      color.L      color.Q      color.C      color^4      color^5  \n    110.340    -1910.288     -627.954     -171.960       21.678      -85.943  \n    color^6  \n    -49.986  \n\n\n[[13]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat  \n      -2067         7411  \n\n\n[[14]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2460.16      7526.96      1059.65      -410.54       295.80        82.62  \n\n\n[[15]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2897.60      8118.13       618.65      -268.13       148.57         8.10  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n    3463.17     -1505.52       609.45      -286.81       158.48        71.83  \n  clarity^7  \n     183.33  \n\n\n[[16]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3376.856     8513.377      607.668     -263.835      142.453        5.506  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   3654.785    -1503.171      612.049     -225.568      124.920       47.356  \n  clarity^7      color.L      color.Q      color.C      color^4      color^5  \n    112.889    -1714.316     -539.239     -127.282       43.649      -60.866  \n    color^6  \n    -49.333"
  },
  {
    "objectID": "posts/2025-05-12-writing-efficient-functions/index.html#exercise-1-helper-functions",
    "href": "posts/2025-05-12-writing-efficient-functions/index.html#exercise-1-helper-functions",
    "title": "Writing Efficient Functions",
    "section": "",
    "text": "Write a function that removes outliers in a dataset. The user should be able to supply the dataset, the variables to remove outliers from, and a threshold on the number of SDs away from the mean used to define outliers.\nHint 1: You will need to calculate a z-score to filter the values! \nHint 2: You might want to consider specifying a default value (e.g., 3) for sd_thresh.\n\nremove_outliers&lt;- function(data, ... , sd_threshold = 3){\n  \n  variables &lt;- as.character(substitute(list(...)))[-1]\n  \n  keep &lt;- rep(TRUE, nrow(data))\n  # dataframe of values to keep\n  \n  for(each in variables){\n    if (!is.numeric(data[[each]])) {\n      warning(paste(\"Variable\", each\n                 , \"is not numeric! Only numeric variables are supported! We cannot drop outliers from this column\"))\n      next\n      # returns error for non-numeric variables\n    }\n    \n    mu &lt;- mean(data[[each]])\n    sd &lt;- sd(data[[each]])\n    z_scores &lt;- (data[[each]] - mu) / sd\n    # find the zscore of each instance of each variable\n    \n    keep &lt;- keep & abs(z_scores) &lt; sd_threshold\n    # filters out values where the zscore is greater than the specified threshold\n      }\n  return (data[keep, ])\n\n  \n}\n\n# [[]] vs [] https://stackoverflow.com/questions/1169456/the-difference-between-bracket-and-double-bracket-for-accessing-the-el\n\nThis function is not the most efficient as it does use a for loop.\n\n\n\n## Testing how your function handles multiple input variables\n\nremove_outliers(diamonds, \n                price, \n                x, \n                y, \n                z)\n\n# A tibble: 52,689 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 52,679 more rows\n\n\n\n## Testing how your function handles an input that isn't numeric\nremove_outliers(diamonds, \n                price, \n                color)\n\nWarning in remove_outliers(diamonds, price, color): Variable color is not\nnumeric! Only numeric variables are supported! We cannot drop outliers from\nthis column\n\n\n# A tibble: 52,734 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 52,724 more rows\n\n\n\n## Testing how your function handles a non-default sd_thresh\nremove_outliers(diamonds, \n                price,\n                x, \n                y, \n                z, \n                sd_threshold = 2)\n\n# A tibble: 50,099 × 10\n   carat cut       color clarity depth table price     x     y     z\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# ℹ 50,089 more rows"
  },
  {
    "objectID": "posts/2025-05-12-writing-efficient-functions/index.html#exercise-2-helper-functions",
    "href": "posts/2025-05-12-writing-efficient-functions/index.html#exercise-2-helper-functions",
    "title": "Writing Efficient Functions",
    "section": "",
    "text": "Write a function that imputes missing values for numeric variables in a dataset. The user should be able to supply the dataset, the variables to impute values for, and a function to use when imputing. Hint 1: You will need to use across() to apply your function, since the user can input multiple variables. Hint 2: The replace_na() function is helpful here!\n\nimpute_missing &lt;- function( data, ..., func = sum){\n  # capture variable names\n  variables &lt;- as.character(substitute(list(...)))[-1]\n  \n   #issues a warning for non-numeric variables and retains them in the dataset without imputing\n  numeric_variables &lt;- variables[sapply(variables, function(x) is.numeric(data[[x]]))]\n  \n  non_numeric_vars &lt;- setdiff(variables, numeric_variables)\n  \n  if(length(non_numeric_vars) &gt; 0) {\n    warning(paste(\"The following variables are non-numeric and will not be imputed:\", paste(non_numeric_vars, collapse = \", \")))\n  }\n  \n  data |&gt;\n    mutate(across(\n      .cols = all_of(numeric_variables),\n      .fns = ~ replace_na(.x, func(.x, na.rm = TRUE))\n    ))\n}\n\nThis function is more efficient than the last one as it uses sapply() and the usage of dplyr makes this function more efficient than the last one.\n\n\n\n## Testing how your function handles multiple input variables\nimpute_missing(flights, \n               arr_delay, \n               dep_delay) \n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n## Testing how your function handles an input that isn't numeric\nimpute_missing(flights, \n               arr_delay, \n               carrier)\n\nWarning in impute_missing(flights, arr_delay, carrier): The following variables\nare non-numeric and will not be imputed: carrier\n\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\n## Testing how your function handles a non-default impute_fun\nimpute_missing(flights, \n               arr_delay, \n               dep_delay, \n               func = median)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;"
  },
  {
    "objectID": "posts/2025-05-12-writing-efficient-functions/index.html#exercise-3-primary-function",
    "href": "posts/2025-05-12-writing-efficient-functions/index.html#exercise-3-primary-function",
    "title": "Writing Efficient Functions",
    "section": "",
    "text": "Write a fit_model() function that fits a specified linear regression model for a specified dataset. The function should:\n\nallow the user to specify if outliers should be removed (TRUE or FALSE)\nallow the user to specify if missing observations should be imputed (TRUE or FALSE)\n\nIf either option is TRUE, your function should call your remove_outliers() or impute_missing() functions to modify the data before the regression model is fit.\n\nfit_model &lt;- function(data, mod_formula, remove_outliers = FALSE, impute_missing = FALSE, ...) {\n  \n  #run helper functions if indicated\n  if (remove_outliers) {\n    data &lt;- remove_outliers(data, ...)\n  }\n  \n  if (impute_missing) {\n    data &lt;- impute_missing(data, ...)\n  }\n  \n  #fit the linear regression model\n  model &lt;- lm(mod_formula, data = data)\n  \n  # Return the fitted model\n  return(model)\n}\n\n\n\n\nfit_model(\n  diamonds,\n  mod_formula = price ~ carat + cut,\n  remove_outliers = TRUE,\n  impute_missing = TRUE,\n  price, \n  carat\n)\n\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2460.16      7526.96      1059.65      -410.54       295.80        82.62  \n\n\n\n\n\nIn the diamonds dataset, we want to understand the relationship between price and size (carat). We want to explore variation along two choices:\n\nThe variables included in the model. We’ll explore 3 sets of variables:\n\nNo further variables (just price and carat)\nAdjusting for cut\nAdjusting for cut and clarity\nAdjusting for cut, clarity, and color\n\nWhether or not to impute missing values\nWhether or not to remove outliers in the carat variable (we’ll define outliers as cases whose carat is over 3 SDs away from the mean)."
  },
  {
    "objectID": "posts/2025-05-12-writing-efficient-functions/index.html#exercise-4-parameters",
    "href": "posts/2025-05-12-writing-efficient-functions/index.html#exercise-4-parameters",
    "title": "Writing Efficient Functions",
    "section": "",
    "text": "First, we need to define the set of parameters we want to iterate the fit_model() function over. The tidyr package has a useful function called crossing() that is useful for generating argument combinations. For each argument, we specify all possible values for that argument and crossing() generates all combinations. Note that you can create a list of formula objects in R with c(y ~ x1, y ~ x1 + x2).\n\ndf_arg_combos &lt;- crossing(\n    impute = c(TRUE, FALSE),\n    remove_outliers = c(TRUE, FALSE), \n    mod = c(y ~ x1, \n            y ~ x1 + x2)\n)\ndf_arg_combos\n\n# A tibble: 8 × 3\n  impute remove_outliers mod      \n  &lt;lgl&gt;  &lt;lgl&gt;           &lt;list&gt;   \n1 FALSE  FALSE           &lt;formula&gt;\n2 FALSE  FALSE           &lt;formula&gt;\n3 FALSE  TRUE            &lt;formula&gt;\n4 FALSE  TRUE            &lt;formula&gt;\n5 TRUE   FALSE           &lt;formula&gt;\n6 TRUE   FALSE           &lt;formula&gt;\n7 TRUE   TRUE            &lt;formula&gt;\n8 TRUE   TRUE            &lt;formula&gt;\n\n\nUse crossing() to create the data frame of argument combinations for our analyses.\n\nparam_sets &lt;- crossing(\n  impute = c(TRUE, FALSE),                           \n  remove_outliers = c(TRUE, FALSE),                   \n  mod = c(                                        \n    price ~ carat,   # No adjustment    \n    \n    price ~ carat + cut,                             \n    price ~ carat + cut + clarity,     \n    \n    # Adjusting for cut, clarity, and color\n    price ~ carat + cut + clarity + color            \n  )\n)\nparam_sets\n\n# A tibble: 16 × 3\n   impute remove_outliers mod      \n   &lt;lgl&gt;  &lt;lgl&gt;           &lt;list&gt;   \n 1 FALSE  FALSE           &lt;formula&gt;\n 2 FALSE  FALSE           &lt;formula&gt;\n 3 FALSE  FALSE           &lt;formula&gt;\n 4 FALSE  FALSE           &lt;formula&gt;\n 5 FALSE  TRUE            &lt;formula&gt;\n 6 FALSE  TRUE            &lt;formula&gt;\n 7 FALSE  TRUE            &lt;formula&gt;\n 8 FALSE  TRUE            &lt;formula&gt;\n 9 TRUE   FALSE           &lt;formula&gt;\n10 TRUE   FALSE           &lt;formula&gt;\n11 TRUE   FALSE           &lt;formula&gt;\n12 TRUE   FALSE           &lt;formula&gt;\n13 TRUE   TRUE            &lt;formula&gt;\n14 TRUE   TRUE            &lt;formula&gt;\n15 TRUE   TRUE            &lt;formula&gt;\n16 TRUE   TRUE            &lt;formula&gt;"
  },
  {
    "objectID": "posts/2025-05-12-writing-efficient-functions/index.html#exercise-5-iterating-over-parameters",
    "href": "posts/2025-05-12-writing-efficient-functions/index.html#exercise-5-iterating-over-parameters",
    "title": "Writing Efficient Functions",
    "section": "",
    "text": "Use pmap() from purrr to apply the fit_model() function to every combination of arguments from diamonds.\n\nparam_sets&lt;-param_sets |&gt;\n  mutate(model = pmap(list(impute, remove_outliers, mod), \n                      function(impute, remove_outliers, mod) {\n                        fit_model(\n                          data = diamonds,\n                          mod_formula = mod,\n                          remove_outliers = remove_outliers,\n                          impute_missing = impute,\n                          price,\n                          carat\n                          # variable to use for outlier removal and imputation\n                          # variables cut, clarity and color are non-numeric\n                        )\n                      }))\n\n\nprint(param_sets$model)\n\n[[1]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat  \n      -2256         7756  \n\n\n[[2]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2701.38      7871.08      1239.80      -528.60       367.91        74.59  \n\n\n[[3]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3187.540     8472.026      713.804     -334.503      188.482        1.663  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4011.681    -1821.922      917.658     -430.047      257.141       26.909  \n  clarity^7  \n    186.742  \n\n\n[[4]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3710.603     8886.129      698.907     -327.686      180.565       -1.207  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4217.535    -1832.406      923.273     -361.995      216.616        2.105  \n  clarity^7      color.L      color.Q      color.C      color^4      color^5  \n    110.340    -1910.288     -627.954     -171.960       21.678      -85.943  \n    color^6  \n    -49.986  \n\n\n[[5]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat  \n      -2067         7411  \n\n\n[[6]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2460.16      7526.96      1059.65      -410.54       295.80        82.62  \n\n\n[[7]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2897.60      8118.13       618.65      -268.13       148.57         8.10  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n    3463.17     -1505.52       609.45      -286.81       158.48        71.83  \n  clarity^7  \n     183.33  \n\n\n[[8]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3376.856     8513.377      607.668     -263.835      142.453        5.506  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   3654.785    -1503.171      612.049     -225.568      124.920       47.356  \n  clarity^7      color.L      color.Q      color.C      color^4      color^5  \n    112.889    -1714.316     -539.239     -127.282       43.649      -60.866  \n    color^6  \n    -49.333  \n\n\n[[9]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat  \n      -2256         7756  \n\n\n[[10]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2701.38      7871.08      1239.80      -528.60       367.91        74.59  \n\n\n[[11]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3187.540     8472.026      713.804     -334.503      188.482        1.663  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4011.681    -1821.922      917.658     -430.047      257.141       26.909  \n  clarity^7  \n    186.742  \n\n\n[[12]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3710.603     8886.129      698.907     -327.686      180.565       -1.207  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   4217.535    -1832.406      923.273     -361.995      216.616        2.105  \n  clarity^7      color.L      color.Q      color.C      color^4      color^5  \n    110.340    -1910.288     -627.954     -171.960       21.678      -85.943  \n    color^6  \n    -49.986  \n\n\n[[13]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat  \n      -2067         7411  \n\n\n[[14]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2460.16      7526.96      1059.65      -410.54       295.80        82.62  \n\n\n[[15]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n   -2897.60      8118.13       618.65      -268.13       148.57         8.10  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n    3463.17     -1505.52       609.45      -286.81       158.48        71.83  \n  clarity^7  \n     183.33  \n\n\n[[16]]\n\nCall:\nlm(formula = mod_formula, data = data)\n\nCoefficients:\n(Intercept)        carat        cut.L        cut.Q        cut.C        cut^4  \n  -3376.856     8513.377      607.668     -263.835      142.453        5.506  \n  clarity.L    clarity.Q    clarity.C    clarity^4    clarity^5    clarity^6  \n   3654.785    -1503.171      612.049     -225.568      124.920       47.356  \n  clarity^7      color.L      color.Q      color.C      color^4      color^5  \n    112.889    -1714.316     -539.239     -127.282       43.649      -60.866  \n    color^6  \n    -49.333"
  }
]
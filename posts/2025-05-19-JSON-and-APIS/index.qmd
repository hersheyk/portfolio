---
title: "JSON and APIs"
author: "Harshini Karthikeyan"
date: '05-19-2025'
format:
  html:
    backgroundcolor: whitesmoke
    monobackgroundcolor: lightsteelblue
    fontcolor: black
    number_sections: yes
#mainfont: default
editor: visual
toc: true
toc_float: true
embed-resources: true
image: dashboard_preview.JPG
---

```{r, warning = FALSE, echo = TRUE}
#| label: load-packages
#| message: false
library(httr)
library(jsonlite)
library(dplyr)
library(purrr)
library(readr)
library(tidyverse)
library(leaflet)
library(knitr)
library(tidyjson)
#eab39c3c6fb6d4f959dbcb4ad3ad9a8205551bc1

```

```{r}
#| label: load-data
capitals_names <- read_lines("https://people.sc.fsu.edu/~jburkardt/datasets/states/state_capitals_name.txt")
capitals_lat_long <- read_lines("https://people.sc.fsu.edu/~jburkardt/datasets/states/state_capitals_ll.txt")
```

```{r}
#| label: dataframe-cleaning
latlon_df <- str_split(capitals_lat_long, "\\s+", simplify = TRUE) |>  
  as.data.frame() |> 
  rename(state = V1, latitude = V2, longitude = V3) |> 
  mutate(state = trimws(state))

capitals_df <- str_split(capitals_names, '"', simplify = TRUE) |>  
  as.data.frame() |> 
  rename(state = V1, capital = V2) |> 
  select(-V3) |> 
  mutate(state = trimws(state))

full_capitals_dataset <- full_join(latlon_df, capitals_df, by = "state")


full_capitals_dataset <- full_capitals_dataset |> 
  mutate(
    capital = str_remove_all(capital, '"'),
    latitude = as.numeric(latitude),
    longitude = as.numeric(longitude)
  )
```

```{r}
#| label: testing

response <- GET("https://api.g7vrd.co.uk/v1/satellite-passes/25544/51.45/-2.5833.json")

space <- response$content |> 
  rawToChar() |>  
  fromJSON()

str(space)


json_tbl <- response$content |> 
  rawToChar() |> 
  as.tbl_json()

json_tbl |>  
  spread_all() |> 
  enter_object("passes") |> 
  gather_array() |>     # if it's a JSON array
  spread_all() |> 
  select(start)
```

```{r}
#| label: API-function
get_pass_times <- function(lat, lon) {
  #Construct the API URL for the given latitude and longitude
  url <- paste0("https://api.g7vrd.co.uk/v1/satellite-passes/25544/", lat, "/", lon, ".json")
  response <- GET(url) #Call the API 

  if (status_code(response) == 200) {
    data <- fromJSON(rawToChar(response$content)) #Convert raw JSON to useable form
    
    if (!is.null(data$passes)) {
      return(head(data$passes$tca, 3)) #If passes exists in the data, extract first three pass times. Note that these are ordered descending, so it should get the earliest three times.
    }
  }

  return(rep(NA, 3))  #Return 3 NAs if unavailable
}
```

```{r}
#| label: Getting-data

capitals_all_passes <- full_capitals_dataset |> 
  mutate(pass_times = pmap(list(latitude, longitude), get_pass_times))

capitals_with_passes <- capitals_all_passes |> 
  mutate(
    pass_time_1 = map_chr(pass_times, ~ if(length(.) >= 1) .[1] else NA), 
    pass_time_2 = map_chr(pass_times, ~ if(length(.) >= 2) .[2] else NA),
    pass_time_3 = map_chr(pass_times, ~ if(length(.) >= 3) .[3] else NA)) |>
  select(-pass_times) |>
  filter(!state %in% c('US', 'PR'))
  #There were two Districts of Columbia in the dataset, one with the wrong latitude, so we dropped the other DC and San Juan of Puerto Rico(not sure why this was showing up).



```

```{r creating labels and pop-ups}

capitals_with_passes <- capitals_with_passes %>%
  arrange(is.na(pass_time_1), pass_time_1) %>%
  rowwise() %>%
  mutate(
    pop_up_html = if (is.na(pass_time_1)) {
      paste0("<b>", capital, "</b><br/>",
             "ISS will not pass over this location in the next 72 hours")
    } else {
      paste0("<b>", toupper(capital), "</b><br/>",
             "Next Three ISS Passtimes:<br/>",
             # read way many articles much about date time formatting and functions, but so happy with how it looks now
             # https://learn.microsoft.com/en-us/dotnet/standard/base-types/standard-date-and-time-format-strings
             format(as_datetime(pass_time_1), "%B %d, %Y  %I:%M %p %Z"),
             "<br/>",
             if_else(!is.na(pass_time_2),
                     (format(as_datetime(pass_time_2), "%B %d, %Y  %I:%M %p %Z")),
                     "No second pass"),
             "<br/>",
             if_else(!is.na(pass_time_3), (format(as_datetime(pass_time_3), "%B %d, %Y  %I:%M %p %Z")), 
                     "No third pass"))
    },  
    
    label_html = htmltools::HTML((paste0(
      "<b>", toupper(capital), "<b><br/>",
      if_else(is.na(pass_time_1),
              "ISS will not pass over this location in the next 72 hours",
              paste("Next ISS Passtime:",
                    format(as_datetime(pass_time_1), "%B %d, %Y  %I:%M %p %Z"))
     ))))
  ) %>%
  ungroup()

# created new columns in the dataframe, because the html options were having issues running within the leaflet plot and to make the code for the plot cleaner
```

```{r}
#dropping NAs from the path
caps<- capitals_with_passes|> filter(!is.na(pass_time_1))

```

```{r}
iss_icon <- icons(
  iconUrl = here::here("pngtree-space-station-probe-icon-png-image_4687961.png"), 
  iconWidth = 30, 
  iconHeight = 30
)

leaflet(capitals_with_passes) |> addTiles() %>%
  addMarkers(lng = ~longitude,
             lat = ~latitude,
             icon = iss_icon,
             label = ~label_html,
             popup = ~pop_up_html
            # so excited to have discovered the use of the tilda('~')
             ) |>
  addPolylines(lng = caps$longitude,
               lat = caps$latitude)

```
